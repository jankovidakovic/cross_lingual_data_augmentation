{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import BartForSequenceClassification, BartForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.utils import PaddingStrategy\n",
    "import evaluate\n",
    "from nltk import sent_tokenize\n",
    "import numpy as np\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from accelerate import Accelerator\n",
    "from transformers import get_scheduler\n",
    "import nltk\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from datasets import ClassLabel\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "PRETRAINED_MODEL_NAME_OR_PATH=\"ainize/bart-base-cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def setup_models():\n",
    "    # initialize models\n",
    "    classification_model = BartForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME_OR_PATH, num_labels=59)\n",
    "    summarization_model = BartForConditionalGeneration.from_pretrained(PRETRAINED_MODEL_NAME_OR_PATH)\n",
    "\n",
    "    # share parameters\n",
    "    summarization_model.model.shared = classification_model.model.shared\n",
    "    summarization_model.model.encoder = classification_model.model.encoder\n",
    "    summarization_model.model.decoder = classification_model.model.decoder\n",
    "\n",
    "    return {\n",
    "        \"summarization\": summarization_model,\n",
    "        \"classification\": classification_model\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ainize/bart-base-cnn were not used when initializing BartForSequenceClassification: ['final_logits_bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at ainize/bart-base-cnn and are newly initialized: ['classification_head.out_proj.weight', 'classification_head.out_proj.bias', 'classification_head.dense.bias', 'classification_head.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "models = setup_models()\n",
    "assert id(models[\"summarization\"].model.shared) == id(models[\"classification\"].model.shared)\n",
    "assert id(models[\"summarization\"].model.encoder) == id(models[\"classification\"].model.encoder)\n",
    "assert id(models[\"summarization\"].model.decoder) == id(models[\"classification\"].model.decoder)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_tokens.weight is Parameter containing:\n",
      "tensor([[ 0.0113,  0.0083, -0.0115,  ...,  0.0084,  0.1087,  0.0126],\n",
      "        [ 0.0123, -0.0161,  0.0099,  ..., -0.0460, -0.0303,  0.0128],\n",
      "        [ 0.0790, -0.0347,  0.0084,  ...,  0.0486,  0.0094,  0.0307],\n",
      "        ...,\n",
      "        [ 0.0131, -0.0308, -0.0453,  ..., -0.0032,  0.0246, -0.0191],\n",
      "        [ 0.0053, -0.0446, -0.0519,  ...,  0.0054,  0.0143, -0.0166],\n",
      "        [ 0.0102, -0.0272, -0.0528,  ...,  0.0231,  0.0057, -0.0126]],\n",
      "       requires_grad=True)\n",
      "embed_tokens.weight is Parameter containing:\n",
      "tensor([[ 0.0113,  0.0083, -0.0115,  ...,  0.0084,  0.1087,  0.0126],\n",
      "        [ 0.0123, -0.0161,  0.0099,  ..., -0.0460, -0.0303,  0.0128],\n",
      "        [ 0.0790, -0.0347,  0.0084,  ...,  0.0486,  0.0094,  0.0307],\n",
      "        ...,\n",
      "        [ 0.0131, -0.0308, -0.0453,  ..., -0.0032,  0.0246, -0.0191],\n",
      "        [ 0.0053, -0.0446, -0.0519,  ...,  0.0054,  0.0143, -0.0166],\n",
      "        [ 0.0102, -0.0272, -0.0528,  ...,  0.0231,  0.0057, -0.0126]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "def print_first_param(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name} is {param}\")\n",
    "        break\n",
    "\n",
    "print_first_param(models[\"classification\"].model.encoder)\n",
    "print_first_param(models[\"summarization\"].model.encoder)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "# we need a:\n",
    "#   -> dataframe loaded with docee examples\n",
    "#   -> tokenizer (bart tokenizer)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME_OR_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/home/jvidakovic/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ace7aa600d340a0bed309caf2801639"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 287113, 'validation': 13368, 'test': 11490}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# bruhus\n",
    "summ_dataset = load_dataset(\"cnn_dailymail\", name=\"3.0.0\")\n",
    "print({split: len(summ_dataset[split]) for split in summ_dataset})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def compose2(f, g):\n",
    "    def composition(*args, **kwargs):\n",
    "        g_output = g(*args, **kwargs)\n",
    "        return f(g_output)\n",
    "    return composition\n",
    "\n",
    "def c(*fs):\n",
    "    def composition(*args, **kwargs):\n",
    "        output = fs[-1](*args, **kwargs)\n",
    "        for f in reversed(fs[:-1]):\n",
    "            output = f(output)\n",
    "        return output\n",
    "    return composition\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0720af0f377253e9\n",
      "Found cached dataset csv (/home/jvidakovic/.cache/huggingface/datasets/csv/default-0720af0f377253e9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f59d28d426f4a27afe145c3d48cd061"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['index', 'title', 'text', 'event_type', 'arguments', 'date', 'metadata'],\n        num_rows: 17559\n    })\n    validation: Dataset({\n        features: ['index', 'title', 'text', 'event_type', 'arguments', 'date', 'metadata'],\n        num_rows: 2195\n    })\n})"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# okay, we got this\n",
    "# cls_dataset = load_dataset(\"csv\", data_files=\"../data/docee/train_all.csv\")\n",
    "# data_files can be a dictionary, where key is the name of the split, and value is path to the split\n",
    "cls_dataset = load_dataset(\"csv\", data_files={\n",
    "    \"train\": \"../data/docee/18091999/train.csv\",\n",
    "    \"validation\": \"../data/docee/18091999/early_stopping.csv\"\n",
    "})\n",
    "cls_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/jvidakovic/.cache/huggingface/datasets/csv/default-0720af0f377253e9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-1b432e07d6b975f8.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'index': [8677, 13606, 10423],\n 'title': ['Simulation of glacial calving and tsunami waves predicts climate change consequences',\n  'Four protesters and two police officers are killed during clashes in Baghdad.',\n  'Italian firm Fiat Chrysler  proposes a merger with French carmaker Renault. The new company will be based in the Netherlands and will be listed on the Milan, Paris and New York stock exchanges.'],\n 'text': ['As natural disasters intensify due to climate change, accurate predictions of weather patterns and mechanisms are greatly needed to mitigate damage. Coastal regions will be the most affected by changing weather, with events such as tsunamis and hurricanes becoming more frequent and life-threatening. While most tsunamis are caused by earthquakes and tectonic activity, the warming of the planet is now increasing the occurrence of tsunamis caused by glacier calving, when chunks of glacier break off and become icebergs. Additionally, glacier calving is predicted to be the main contributor to sea level rise in the near future. Now, researchers at the School of Engineering and Applied Science have created a computer model that can accurately simulate those dynamics. In a new study, published in the recently established journal Nature Communications Earth & Environment, Penn engineers describe a new simulation that models three key aspects: the ice fracture mechanics within the glacier, the fluid dynamics of the surrounding ocean water, and the interaction between the two. The researchers employed a technique known as the material point method (MPM) which is used for a simulating the interactions between matter of different phases. Their study shows that this technique is capable of accurately describing glacial calving and resulting tsunami waves. By demonstrating their model’s predictive capabilities, the researchers are refining the empirical calving laws used in large-scale earth-system models, as well as improving hazard assessments and mitigation measures in coastal regions, which are essential in the context of climate change. The study was led by Joshuah Wolper, then a graduate student in Penn Engineering’s Department of Computer and Information Sciences (CIS) and current postdoctoral fellow in Mechanical Engineering and Applied Mechanics (MEAM), Chenfanfu Jiang, then assistant professor in CIS, now an assistant professor in the Department of Mathematics at UCLA, and Professor Johan Gaume, head of SLAB, the EPFL Snow and Avalanche Simulation Laboratory in Switzerland. This story is by Melissa Pappas. Read more at Penn Engineering Today.   ',\n  'BAGHDAD (Reuters) - Six Iraqis including two police officers were killed and scores were wounded in Baghdad and other cities on Monday in clashes with security forces, medical and security sources said, as anti-government unrest resumed after a lull of several weeks.\\nThree protesters succumbed to their wounds at a Baghdad hospital after police fired live rounds in Tayaran Square, the sources said. Two protesters were shot by live bullets while a third was hit by a tear gas canister, they said.\\nA fourth demonstrator was shot dead by police in the Shi’ite holy city of Kerbala, the sources added.\\nProtesters threw petrol bombs and stones at police who responded with tear gas and stun grenades, Reuters witnesses said.\\n“They (security forces) should stop shooting and aiming, who are they and who are we? Both sides are Iraqis. So why are you killing your brothers?” said one woman protester in Baghdad who declined to give her name.\\nThree Katyusha rockets fell inside the capital’s heavily fortified Green Zone which houses government buildings and foreign missions, police sources told Reuters. The rockets were launched from Zafaraniyah district outside Baghdad, the sources said, adding that two rockets landed near the U.S. embassy.\\nIn the Iraqi oil city of Basra, two policemen were struck and killed by a civilian car during a protest, security sources said. The driver was trying to avoid the scene of clashes between protesters and security forces when he drove into the two officers, they said.\\nElsewhere in southern Iraq, hundreds of protesters burned tires and blocked main roads in several cities, including Nassiriya, Kerbala and Amara. They say Prime Minister Adel Abdul Mahdi has not fulfilled promises including naming a new government acceptable to Iraqis.\\nBaghdad police said its forces had reopened all roads that were closed by “violent gatherings”. It said 14 officers were wounded near Tahrir square, including some with head wounds and broken bones.\\nTraffic was disrupted on a highway linking Baghdad to southern cities, a Reuters witness said. Production in southern oilfields was unaffected by the unrest, oil officials said.\\nMass protests have gripped Iraq since Oct. 1, with mostly young protesters demanding an overhaul of a political system they see as profoundly corrupt and as keeping most Iraqis in poverty. More than 450 people have been killed.\\nNumbers had dwindled but protests resumed last week as demonstrators sought to keep up momentum after attention turned to the threat of a U.S.-Iran conflict following Washington’s killing of Tehran’s top general in an air strike inside Iraq.\\nThe killing of Qassem Soleimani, to which Tehran responded with a ballistic missile attack on two Iraqi military bases housing U.S. troops, has highlighted the influence of some foreign powers in Iraq, especially Iran and the United States.\\n',\n  'Fiat Chrysler has made a \"transformative\" merger proposal for French carmaker Renault, the Italian firm said on Monday. The combined business would be 50% owned by Fiat shareholders and 50% by Renault stockholders.\\nThe carmaker said the merger would create a global automotive leader, with 8.7 million vehicle sales.\\nCarmakers have faced pressure to consolidate amid major industry shifts, including towards electric vehicles. Shares in both companies rose strongly following the announcement.\\nIn a statement, Fiat Chrysler (FCA) said the planned merger would create a \"world leader in the rapidly changing automotive industry with a strong position in transforming technologies, including electrification and autonomous driving\". Fiat said that if the firms\\' 2018 financial results were totted up, the combined company\\'s annual revenues would be nearly €170bn (£149.6bn; $190.5bn), with operating profit of more than €10bn and net profit of more than €8bn. No plant closures would be caused as a result of the tie-up, the carmaker said. It will aim to save €5bn a year by sharing development costs on technology such as electric vehicles and self-driving cars. It is thought some managerial positions may be lost, but the companies will be keen to show that production-line jobs are being preserved.\\nThe new company will be based in the Netherlands and will be listed on the Milan, Paris and New York stock exchanges.\\nTo make the merger one of equals, the slightly-wealthier FCA will pay a special dividend of €2.5bn and sell its Comau robotics business.\\nThe proposal will be considered by the Renault board. Who will lead the new entity and what it might be called are not yet decided.\\nIf the plan goes ahead, Nissan and the French government will own about 7.5% apiece of the new, merged company.\\nThe French government favours the merger but wants more details before giving its final approval, a spokeswoman said. The Italian government may want to acquire a share of the new firm to balance France\\'s stake, said a politician from the Northern League, the country\\'s largest party, according to Reuters.\\nBy sales, the new company will be number four in North America, number two in the region which covers Europe, the Middle East and Africa and the biggest in Latin America.\\nIndustry shifts toward electric models, along with stricter emissions standards and the development of new technologies for autonomous vehicles, have put increasing pressure on carmakers to consolidate. Renault already has an alliance with Japan\\'s Nissan, in which research costs and parts are shared. The companies own shares in each other, too. Renault owns 43.4% of Nissan\\'s shares and Nissan owns 15% of Renault. The former chief executive of both Nissan and Renault, Carlos Ghosn, is awaiting trial following his fourth arrest amid allegations of financial misconduct. The allegations have put a strain on the 20-year-old alliance, which also includes Japan\\'s Mitsubishi Motors.\\nNew entrants in the motoring sector such as Tesla, as well as cash-rich companies developing driverless technology such as Amazon and Google-owned Waymo, are putting pressure on older and often heavily indebted carmakers to keep up. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'],\n 'event_type': ['Tsunamis',\n  'Protest_Online Condemnation',\n  'Organization Merge'],\n 'arguments': [\"[{'start': 335, 'end': 367, 'type': 'Causes', 'text': 'earthquakes and tectonic activity'}, {'start': 370, 'end': 394, 'type': 'Causes', 'text': 'the warming of the planet'}, {'start': 635, 'end': 694, 'type': 'People/Organization who predicted the disaster', 'text': 'researchers at the School of Engineering and Applied Science'}]\",\n  \"[{'start': 20, 'end': 95, 'type': 'Casualties and Losses', 'text': 'Six Iraqis including two police officers were killed and scores were wounded'}, {'start': 100, 'end': 123, 'type': 'Location', 'text': 'Baghdad and other cities'}, {'start': 128, 'end': 133, 'type': 'Date', 'text': 'Monday'}, {'start': 268, 'end': 282, 'type': 'Casualties and Losses', 'text': 'Three protester'}, {'start': 367, 'end': 380, 'type': 'Location', 'text': 'Tayaran Square'}]\",\n  \"[{'start': 0, 'end': 12, 'type': 'Acquiree', 'text': 'Fiat Chrysler'}, {'start': 69, 'end': 76, 'type': 'The industry in which the organization operates', 'text': 'carmaker'}, {'start': 78, 'end': 84, 'type': 'Acquiree', 'text': 'Renault'}, {'start': 112, 'end': 117, 'type': 'Date', 'text': 'Monday'}, {'start': 164, 'end': 167, 'type': 'The leader of the merged organization', 'text': 'Fiat'}, {'start': 193, 'end': 199, 'type': 'The leader of the merged organization', 'text': 'Renault'}]\"],\n 'date': [None, 'January 2020', 'May 2019'],\n 'metadata': [None, \"['(Reuters)']\", \"['(BBC)']\"]}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_dataset[\"train\"].shuffle(42).select(range(100))[:3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 100\n",
    "\n",
    "def process_summary_example(examples):\n",
    "    # tokenize the article\n",
    "    batch_encoding = tokenizer(\n",
    "        examples[\"article\"],\n",
    "        max_length=max_input_length,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # tokenize the labels\n",
    "    tokenized_highlights = tokenizer(\n",
    "        examples[\"highlights\"],\n",
    "        max_length=max_target_length,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    batch_encoding[\"labels\"] = tokenized_highlights[\"input_ids\"]\n",
    "    return batch_encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/288 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3616fa693d0a46f59d39e09a5b5a74fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jvidakovic/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de/cache-b0bb298f8937ca1c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fb6abba65f64ed781393cf0c41f66a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_cnn = summ_dataset.map(process_summary_example, batched=True, remove_columns=[\"id\", \"article\", \"highlights\"])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_cnn[\"train\"].features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "{'rouge1': 0.923076923076923,\n 'rouge2': 0.7272727272727272,\n 'rougeL': 0.923076923076923,\n 'rougeLsum': 0.923076923076923}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#import evaluate\n",
    "rouge_score = evaluate.load(\"rouge\")\n",
    "\n",
    "generated_summary = \"I absolutely loved reading the Hunger Games\"\n",
    "reference_summary = \"I loved reading the Hunger Games\"\n",
    "\n",
    "scores = rouge_score.compute(\n",
    "    predictions=[generated_summary],\n",
    "    references=[reference_summary]\n",
    ")\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def compute_rouge(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # Compute ROUGE scores\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract the median scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\n",
    "summ_data_collator = DataCollatorForSeq2Seq(tokenizer, model=models[\"summarization\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'input_ids': [0,\n   1640,\n   16256,\n   43,\n   11957,\n   6,\n   8,\n   110,\n   4085,\n   40,\n   28,\n   39582,\n   4,\n   280,\n   189,\n   2369,\n   101,\n   41,\n   43962,\n   2329,\n   1580,\n   6,\n   53,\n   77,\n   525,\n   19678,\n   163,\n   8508,\n   7485,\n   1120,\n   1403,\n   12445,\n   1276,\n   7,\n   492,\n   65,\n   9,\n   69,\n   33473,\n   7,\n   10,\n   12443,\n   6,\n   69,\n   19501,\n   11153,\n   62,\n   19,\n   380,\n   414,\n   4,\n   85,\n   4596,\n   11,\n   411,\n   1484,\n   2806,\n   28748,\n   3277,\n   4,\n   280,\n   3911,\n   8,\n   885,\n   9725,\n   69,\n   4,\n   22,\n   100,\n   802,\n   38,\n   21,\n   164,\n   7,\n   244,\n   42,\n   65,\n   621,\n   54,\n   38,\n   218,\n   75,\n   216,\n   6,\n   53,\n   5,\n   754,\n   14,\n   98,\n   171,\n   82,\n   64,\n   33,\n   10,\n   301,\n   5064,\n   6,\n   14,\n   18,\n   1256,\n   380,\n   60,\n   163,\n   8508,\n   7485,\n   1120,\n   174,\n   3480,\n   10515,\n   229,\n   14740,\n   4,\n   264,\n   189,\n   619,\n   10346,\n   11,\n   69,\n   19501,\n   30,\n   10,\n   723,\n   476,\n   4,\n   22,\n   22086,\n   13,\n   70,\n   5,\n   323,\n   8,\n   8786,\n   60,\n   10,\n   1129,\n   15,\n   10,\n   622,\n   1842,\n   11,\n   69,\n   766,\n   1166,\n   4,\n   22,\n   100,\n   216,\n   42,\n   1445,\n   3251,\n   16,\n   203,\n   2671,\n   87,\n   70,\n   9,\n   201,\n   4,\n   38,\n   67,\n   216,\n   38,\n   437,\n   95,\n   5,\n   34697,\n   72,\n   3480,\n   1395,\n   12881,\n   5,\n   21341,\n   9,\n   5,\n   1842,\n   4,\n   125,\n   5,\n   476,\n   14,\n   39582,\n   163,\n   8508,\n   7485,\n   1120,\n   18,\n   4085,\n   21,\n   414,\n   5774,\n   9,\n   9186,\n   11729,\n   31,\n   12125,\n   12,\n   13139,\n   44392,\n   15029,\n   4,\n   85,\n   1364,\n   15,\n   10,\n   2007,\n   32093,\n   9322,\n   53,\n   1239,\n   24,\n   7,\n   10,\n   203,\n   723,\n   672,\n   6,\n   309,\n   7,\n   886,\n   3073,\n   3067,\n   824,\n   11,\n   764,\n   2659,\n   4,\n   407,\n   239,\n   6,\n   14,\n   24,\n   16,\n   602,\n   292,\n   25705,\n   6,\n   10,\n   38676,\n   219,\n   9,\n   11593,\n   17385,\n   6,\n   10633,\n   8,\n   41,\n   42466,\n   118,\n   10974,\n   6,\n   8,\n   55,\n   87,\n   843,\n   323,\n   813,\n   7,\n   3008,\n   15948,\n   15,\n   316,\n   82,\n   4,\n   252,\n   32,\n   37213,\n   411,\n   33473,\n   31,\n   9398,\n   8,\n   12956,\n   30712,\n   106,\n   88,\n   411,\n   11940,\n   4,\n   22,\n   133,\n   4864,\n   9,\n   5,\n   9398,\n   8,\n   11940,\n   1186,\n   31,\n   973,\n   7,\n   1510,\n   8,\n   680,\n   130,\n   4095,\n   8,\n   920,\n   15029,\n   6,\n   65,\n   21771,\n   1763,\n   8,\n   65,\n   2138,\n   8,\n   2761,\n   12,\n   179,\n   12,\n   4656,\n   1763,\n   60,\n   5,\n   1131,\n   1312,\n   26,\n   11,\n   10,\n   445,\n   4,\n   20,\n   3206,\n   9,\n   15948,\n   16,\n   7,\n   28,\n   8144,\n   62,\n   273,\n   4,\n   96,\n   628,\n   494,\n   6,\n   5,\n   1131,\n   1312,\n   16,\n   1884,\n   7,\n   946,\n   10,\n   7362,\n   13,\n   70,\n   316,\n   1484,\n   4,\n   1398,\n   18,\n   141,\n   5,\n   2422,\n   12313,\n   1364,\n   6,\n   309,\n   7,\n   886,\n   3073,\n   3067,\n   824,\n   4,\n   9867,\n   6,\n   110,\n   2138,\n   782,\n   10,\n   12855,\n   7,\n   1871,\n   39,\n   301,\n   6,\n   50,\n   23,\n   513,\n   120,\n   160,\n   9,\n   11481,\n   26499,\n   6,\n   8,\n   47,\n   214,\n   2882,\n   7,\n   492,\n   123,\n   65,\n   9,\n   14314,\n   4,\n   125,\n   172,\n   24,\n   4072,\n   66,\n   14,\n   110,\n   12855,\n   16,\n   45,\n   10,\n   914,\n   13,\n   123,\n   6,\n   8,\n   24,\n   18,\n   1402,\n   39,\n   809,\n   74,\n   10363,\n   24,\n   4,\n   2486,\n   2138,\n   64,\n   172,\n   120,\n   15,\n   10,\n   107,\n   12,\n   3479,\n   2445,\n   889,\n   13,\n   10,\n   12855,\n   567,\n   31,\n   41,\n   6757,\n   12125,\n   54,\n   962,\n   4,\n   5359,\n   14,\n   40,\n   173,\n   66,\n   480,\n   50,\n   45,\n   6,\n   8,\n   86,\n   115,\n   422,\n   66,\n   13,\n   123,\n   4,\n   28013,\n   6,\n   47,\n   8,\n   110,\n   2138,\n   115,\n   356,\n   13,\n   277,\n   13160,\n   12,\n   26111,\n   12125,\n   891,\n   101,\n   31954,\n   480,\n   224,\n   6,\n   80,\n   55,\n   10384,\n   6,\n   147,\n   5,\n   12125,\n   18,\n   12855,\n   965,\n   75,\n   14756,\n   13,\n   39,\n   2761,\n   6,\n   5,\n   13160,\n   4,\n   125,\n   2085,\n   110,\n   12855,\n   16,\n   10,\n   914,\n   13,\n   39,\n   2761,\n   2],\n  'attention_mask': [1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1],\n  'labels': [0,\n   1301,\n   19678,\n   163,\n   8508,\n   7485,\n   1120,\n   1276,\n   7,\n   492,\n   10,\n   12855,\n   7,\n   10,\n   12443,\n   479,\n   50118,\n   250,\n   92,\n   3034,\n   586,\n   1147,\n   69,\n   7096,\n   15220,\n   28748,\n   3277,\n   13,\n   411,\n   12855,\n   1484,\n   479,\n   2]},\n {'input_ids': [0,\n   1640,\n   16256,\n   43,\n   4148,\n   5,\n   231,\n   212,\n   9,\n   587,\n   8008,\n   6,\n   764,\n   3071,\n   35168,\n   8,\n   5815,\n   315,\n   28561,\n   2794,\n   66,\n   11,\n   760,\n   9,\n   1105,\n   6,\n   39062,\n   1057,\n   927,\n   841,\n   23,\n   5,\n   25281,\n   2689,\n   11,\n   764,\n   3071,\n   6,\n   886,\n   4,\n   20,\n   3575,\n   5852,\n   21,\n   5,\n   78,\n   655,\n   5454,\n   815,\n   10433,\n   914,\n   480,\n   10,\n   10025,\n   92,\n   14131,\n   13,\n   5,\n   232,\n   18,\n   2674,\n   2414,\n   11,\n   10,\n   1212,\n   63,\n   40228,\n   56,\n   648,\n   7,\n   28527,\n   4,\n   9430,\n   3916,\n   2787,\n   5,\n   814,\n   13,\n   4944,\n   6,\n   18265,\n   5957,\n   3350,\n   4894,\n   23908,\n   1602,\n   5,\n   1151,\n   1827,\n   22,\n   33272,\n   9,\n   10,\n   92,\n   3567,\n   13,\n   470,\n   4191,\n   72,\n   7817,\n   124,\n   23,\n   4338,\n   31,\n   14,\n   17832,\n   4783,\n   1559,\n   122,\n   24,\n   18,\n   543,\n   45,\n   7,\n   619,\n   10,\n   1402,\n   22531,\n   4,\n   13379,\n   4740,\n   15331,\n   6,\n   12474,\n   25124,\n   35517,\n   8,\n   7782,\n   2178,\n   38232,\n   7,\n   146,\n   426,\n   55,\n   3571,\n   58,\n   70,\n   233,\n   9,\n   5,\n   1026,\n   3693,\n   13989,\n   676,\n   4,\n   40308,\n   29130,\n   58,\n   7460,\n   7,\n   694,\n   4149,\n   23,\n   5,\n   253,\n   9,\n   349,\n   457,\n   4,\n   1648,\n   55,\n   11676,\n   352,\n   6,\n   3016,\n   426,\n   58,\n   5668,\n   30,\n   4511,\n   4518,\n   14,\n   794,\n   6666,\n   472,\n   422,\n   19,\n   5,\n   1011,\n   31,\n   1718,\n   12,\n   17230,\n   66,\n   137,\n   6475,\n   7,\n   1451,\n   5,\n   9375,\n   7551,\n   4,\n   287,\n   5,\n   13989,\n   12273,\n   7,\n   2458,\n   5,\n   1786,\n   9,\n   63,\n   291,\n   212,\n   191,\n   6,\n   24,\n   18,\n   543,\n   7,\n   30030,\n   95,\n   141,\n   203,\n   5,\n   1267,\n   34,\n   18467,\n   11,\n   5,\n   29970,\n   675,\n   4,\n   2597,\n   1613,\n   16,\n   5,\n   4724,\n   7,\n   19665,\n   1741,\n   19,\n   5,\n   1492,\n   9,\n   5,\n   177,\n   13,\n   10,\n   386,\n   4,\n   21226,\n   5332,\n   32,\n   723,\n   87,\n   655,\n   137,\n   150,\n   5,\n   346,\n   9,\n   893,\n   963,\n   34,\n   7113,\n   31,\n   158,\n   11,\n   5,\n   8008,\n   637,\n   7,\n   291,\n   11,\n   570,\n   4,\n   83,\n   617,\n   237,\n   32,\n   278,\n   7,\n   28,\n   355,\n   30,\n   2760,\n   4,\n   374,\n   299,\n   9,\n   42,\n   6,\n   5,\n   92,\n   191,\n   16,\n   5,\n   78,\n   9,\n   10,\n   92,\n   1897,\n   1012,\n   8,\n   433,\n   659,\n   432,\n   19,\n   7481,\n   6,\n   4944,\n   8,\n   35232,\n   10699,\n   966,\n   68,\n   5987,\n   153,\n   81,\n   799,\n   107,\n   4,\n   152,\n   1955,\n   189,\n   18100,\n   13276,\n   5,\n   68,\n   245,\n   4,\n   134,\n   325,\n   682,\n   1199,\n   30,\n   987,\n   25106,\n   13,\n   5,\n   2370,\n   2275,\n   815,\n   6,\n   5,\n   16386,\n   1037,\n   1267,\n   11,\n   5,\n   232,\n   6,\n   53,\n   24,\n   3372,\n   10,\n   7182,\n   20418,\n   11,\n   923,\n   9,\n   5,\n   986,\n   13989,\n   432,\n   4,\n   767,\n   7,\n   4720,\n   8214,\n   34714,\n   6,\n   1029,\n   12,\n   42205,\n   1945,\n   8,\n   394,\n   9,\n   5,\n   92,\n   13989,\n   3468,\n   6,\n   5854,\n   412,\n   10433,\n   2009,\n   6,\n   22,\n   627,\n   539,\n   8,\n   5,\n   177,\n   1495,\n   34,\n   1410,\n   15,\n   8617,\n   113,\n   11,\n   5,\n   121,\n   4,\n   104,\n   7586,\n   91,\n   2046,\n   99,\n   74,\n   3871,\n   654,\n   107,\n   434,\n   11,\n   144,\n   97,\n   4510,\n   34,\n   57,\n   2984,\n   11,\n   5,\n   78,\n   80,\n   1724,\n   9,\n   5,\n   13989,\n   4,\n   8214,\n   34714,\n   108,\n   950,\n   16,\n   10,\n   2654,\n   1246,\n   9,\n   42,\n   6379,\n   7791,\n   4,\n   91,\n   7448,\n   472,\n   145,\n   3148,\n   66,\n   9,\n   2992,\n   2644,\n   142,\n   9,\n   10,\n   3078,\n   6064,\n   19,\n   10,\n   11025,\n   1380,\n   45,\n   98,\n   251,\n   536,\n   4,\n   152,\n   983,\n   1191,\n   6,\n   151,\n   841,\n   32,\n   421,\n   7,\n   4562,\n   5854,\n   412,\n   18,\n   1273,\n   983,\n   12319,\n   136,\n   188,\n   469,\n   412,\n   6,\n   277,\n   92,\n   950,\n   442,\n   49,\n   13989,\n   7323,\n   4,\n   623,\n   968,\n   4251,\n   229,\n   5870,\n   8,\n   871,\n   12470,\n   40,\n   1004,\n   66,\n   13,\n   5854,\n   8,\n   188,\n   469,\n   412,\n   4067,\n   4,\n   22,\n   170,\n   214,\n   95,\n   15,\n   2],\n  'attention_mask': [1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1],\n  'labels': [0,\n   133,\n   291,\n   212,\n   13989,\n   191,\n   3772,\n   42,\n   983,\n   479,\n   50118,\n   17608,\n   34,\n   1714,\n   8617,\n   187,\n   63,\n   17692,\n   11,\n   8008,\n   479,\n   50118,\n   6323,\n   864,\n   549,\n   1492,\n   2624,\n   5391,\n   9686,\n   8,\n   12291,\n   240,\n   7,\n   464,\n   479,\n   2]}]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [tokenized_cnn[i] for i in range(2)]\n",
    "features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[    0,  1640, 16256,  ...,    39,  2761,     2],\n        [    0,  1640, 16256,  ...,    95,    15,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[    0,  1301, 19678,   163,  8508,  7485,  1120,  1276,     7,   492,\n            10, 12855,     7,    10, 12443,   479, 50118,   250,    92,  3034,\n           586,  1147,    69,  7096, 15220, 28748,  3277,    13,   411, 12855,\n          1484,   479,     2,  -100,  -100,  -100],\n        [    0,   133,   291,   212, 13989,   191,  3772,    42,   983,   479,\n         50118, 17608,    34,  1714,  8617,   187,    63, 17692,    11,  8008,\n           479, 50118,  6323,   864,   549,  1492,  2624,  5391,  9686,     8,\n         12291,   240,     7,   464,   479,     2]]), 'decoder_input_ids': tensor([[    2,     0,  1301, 19678,   163,  8508,  7485,  1120,  1276,     7,\n           492,    10, 12855,     7,    10, 12443,   479, 50118,   250,    92,\n          3034,   586,  1147,    69,  7096, 15220, 28748,  3277,    13,   411,\n         12855,  1484,   479,     2,     1,     1],\n        [    2,     0,   133,   291,   212, 13989,   191,  3772,    42,   983,\n           479, 50118, 17608,    34,  1714,  8617,   187,    63, 17692,    11,\n          8008,   479, 50118,  6323,   864,   549,  1492,  2624,  5391,  9686,\n             8, 12291,   240,     7,   464,   479]])}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ_data_collator(features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "tokenized_cnn.set_format(\"torch\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_cnn,\n",
    "    shuffle=True,\n",
    "    collate_fn=summ_data_collator,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_cnn,\n",
    "    collate_fn=summ_data_collator,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "optimizer = AdamW(models[\"summarization\"].parameters(), lr=2e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    models[\"summarization\"], optimizer, train_dataloader, eval_dataloader\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "\n",
    "num_train_epochs = 1\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch progress:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c53143e31c847ee8d4c6e6da6e61001"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch step:   0%|          | 0/3342 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0242768f3d694a36a56ee25d76b9944d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: {'rouge1': 25.981, 'rouge2': 14.579, 'rougeL': 22.3367, 'rougeLsum': 24.8108}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_train_epochs), total=num_train_epochs, desc=\"Epoch progress\"):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"Epoch step\", leave=False):\n",
    "        # pass through model\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # okay, this works\n",
    "        # but we cannot iterate over the two dataloaders with knowing which batch we got\n",
    "        #   which means -> we got to do the iteration manually\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "            )  # aha! we can plug the generation parameters here\n",
    "\n",
    "            generated_tokens = accelerator.pad_across_processes(\n",
    "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # If we did not pad to max length, we need to pad the labels too\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "            labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "            # Replace -100 in the labels as we can't decode them\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens[0]\n",
    "            decoded_preds = tokenizer.batch_decode(\n",
    "                generated_tokens, skip_special_tokens=True\n",
    "            )\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            decoded_preds, decoded_labels = postprocess_text(\n",
    "                decoded_preds, decoded_labels\n",
    "            )\n",
    "\n",
    "            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "            # evaluation loop is fine for summarization but we need it for classification as well\n",
    "\n",
    "    # Compute metrics\n",
    "    result = rouge_score.compute()\n",
    "    # Extract the median ROUGE scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    print(f\"Epoch {epoch}:\", result)\n",
    "\n",
    "    output_dir = \"./test_summ_train\"\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_tokens.weight is Parameter containing:\n",
      "tensor([[ 0.0110,  0.0082, -0.0107,  ...,  0.0088,  0.1086,  0.0112],\n",
      "        [ 0.0123, -0.0161,  0.0099,  ..., -0.0460, -0.0303,  0.0128],\n",
      "        [ 0.0785, -0.0346,  0.0086,  ...,  0.0478,  0.0098,  0.0302],\n",
      "        ...,\n",
      "        [ 0.0131, -0.0308, -0.0453,  ..., -0.0032,  0.0246, -0.0191],\n",
      "        [ 0.0053, -0.0446, -0.0519,  ...,  0.0054,  0.0143, -0.0166],\n",
      "        [ 0.0102, -0.0272, -0.0527,  ...,  0.0231,  0.0057, -0.0126]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "embed_tokens.weight is Parameter containing:\n",
      "tensor([[ 0.0110,  0.0082, -0.0107,  ...,  0.0088,  0.1086,  0.0112],\n",
      "        [ 0.0123, -0.0161,  0.0099,  ..., -0.0460, -0.0303,  0.0128],\n",
      "        [ 0.0785, -0.0346,  0.0086,  ...,  0.0478,  0.0098,  0.0302],\n",
      "        ...,\n",
      "        [ 0.0131, -0.0308, -0.0453,  ..., -0.0032,  0.0246, -0.0191],\n",
      "        [ 0.0053, -0.0446, -0.0519,  ...,  0.0054,  0.0143, -0.0166],\n",
      "        [ 0.0102, -0.0272, -0.0527,  ...,  0.0231,  0.0057, -0.0126]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print_first_param(models[\"classification\"].model.encoder)\n",
    "print_first_param(models[\"summarization\"].model.encoder)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def get_param_list(model):\n",
    "    return [\n",
    "        param for param in model.shared.parameters()\n",
    "    ] + [\n",
    "        param for param in model.encoder.parameters()\n",
    "    ] + [\n",
    "        param for param in model.decoder.parameters()\n",
    "    ]\n",
    "\n",
    "cls_param_list = get_param_list(models[\"classification\"].model)\n",
    "summ_param_list = get_param_list(models[\"summarization\"].model)\n",
    "for cls_param, summ_param in zip(cls_param_list, summ_param_list):\n",
    "    if not torch.all(torch.eq(cls_param, summ_param)):\n",
    "        raise RuntimeError(\"Shared parameters are not equal!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.shared.weight is Parameter containing:\n",
      "tensor([[ 0.0110,  0.0082, -0.0107,  ...,  0.0088,  0.1086,  0.0112],\n",
      "        [ 0.0123, -0.0161,  0.0099,  ..., -0.0460, -0.0303,  0.0128],\n",
      "        [ 0.0785, -0.0346,  0.0086,  ...,  0.0478,  0.0098,  0.0302],\n",
      "        ...,\n",
      "        [ 0.0131, -0.0308, -0.0453,  ..., -0.0032,  0.0246, -0.0191],\n",
      "        [ 0.0053, -0.0446, -0.0519,  ...,  0.0054,  0.0143, -0.0166],\n",
      "        [ 0.0102, -0.0272, -0.0527,  ...,  0.0231,  0.0057, -0.0126]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in models[\"classification\"].named_parameters():\n",
    "    print(f\"{name} is {param}\")\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{'train': ['Military Exercise',\n  'Fire',\n  'Air crash',\n  'Droughts',\n  'Awards ceremony',\n  'Diplomatic Talks _ Diplomatic_Negotiation_ Summit Meeting',\n  'Road Crash',\n  'Riot',\n  'Armed Conflict',\n  'Government Policy Changes',\n  'Withdraw from an Organization',\n  'Famous Person - Sick',\n  'Strike',\n  'Government Job change - Election',\n  'New achievements in aerospace',\n  'Organization Closed',\n  'Protest_Online Condemnation',\n  'Hurricanes_Tornado_Storm_Blizzard',\n  'Famous Person - Commit Crime - Release',\n  'Earthquakes',\n  'Famous Person - Commit Crime - Accuse',\n  'Famous Person - Commit Crime - Arrest',\n  'Diplomatic Visit',\n  'Bank Robbery',\n  'Financial Aid',\n  'Famous Person - Marriage',\n  'Mine Collapses',\n  'Government Job change - Appoint_Inauguration',\n  'Famous Person - Commit Crime - Sentence',\n  'Volcano Eruption',\n  'Disease Outbreaks',\n  'Famous Person - Death',\n  'Government Job change - Resignation_Dismissal',\n  'Mass Poisoning',\n  'Train collisions',\n  'Gas explosion',\n  'Famous Person - Divorce',\n  'Mudslides',\n  'Tear Up Agreement',\n  'Sports Competition',\n  'Organization Merge',\n  'Break historical records',\n  'Financial Crisis',\n  'Famous Person - Commit Crime - Investigate',\n  'Environment Pollution',\n  'Sign Agreement',\n  'Insect Disaster',\n  'Join in an Organization',\n  'Famous Person - Give a speech',\n  'Floods',\n  'Tsunamis',\n  'Organization Fine',\n  'New wonders in nature',\n  'Shipwreck',\n  'Famine',\n  'New archeological discoveries',\n  'Organization Established',\n  'Famous Person - Recovered',\n  'Regime Change'],\n 'validation': ['Join in an Organization',\n  'Fire',\n  'Earthquakes',\n  'Armed Conflict',\n  'Famous Person - Recovered',\n  'Road Crash',\n  'Government Job change - Resignation_Dismissal',\n  'Famous Person - Commit Crime - Sentence',\n  'Disease Outbreaks',\n  'Organization Merge',\n  'New wonders in nature',\n  'Organization Established',\n  'Volcano Eruption',\n  'Gas explosion',\n  'Government Job change - Appoint_Inauguration',\n  'Hurricanes_Tornado_Storm_Blizzard',\n  'Bank Robbery',\n  'Environment Pollution',\n  'Protest_Online Condemnation',\n  'Famous Person - Commit Crime - Release',\n  'Strike',\n  'Famous Person - Commit Crime - Accuse',\n  'Government Job change - Election',\n  'Break historical records',\n  'Mass Poisoning',\n  'Sports Competition',\n  'Mudslides',\n  'Organization Closed',\n  'Famous Person - Commit Crime - Arrest',\n  'Famous Person - Give a speech',\n  'Sign Agreement',\n  'Famous Person - Commit Crime - Investigate',\n  'Tsunamis',\n  'Riot',\n  'Air crash',\n  'Diplomatic Talks _ Diplomatic_Negotiation_ Summit Meeting',\n  'Mine Collapses',\n  'Insect Disaster',\n  'Train collisions',\n  'Shipwreck',\n  'Withdraw from an Organization',\n  'Famous Person - Death',\n  'Financial Aid',\n  'Floods',\n  'Awards ceremony',\n  'Financial Crisis',\n  'New achievements in aerospace',\n  'Diplomatic Visit',\n  'Tear Up Agreement',\n  'New archeological discoveries',\n  'Droughts',\n  'Military Exercise',\n  'Organization Fine',\n  'Famine',\n  'Government Policy Changes',\n  'Famous Person - Sick',\n  'Famous Person - Marriage',\n  'Famous Person - Divorce',\n  'Regime Change']}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_names = cls_dataset.unique(\"event_type\")\n",
    "event_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jvidakovic/.cache/huggingface/datasets/csv/default-0720af0f377253e9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-5f6bf4a5560153b2.arrow\n",
      "Loading cached processed dataset at /home/jvidakovic/.cache/huggingface/datasets/csv/default-0720af0f377253e9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-d42b77ea8f3482ef.arrow\n"
     ]
    }
   ],
   "source": [
    "cls_dataset = cls_dataset.cast_column(\"event_type\", ClassLabel(num_classes=len(event_names[\"train\"]), names=sorted(event_names[\"train\"])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "{'index': Value(dtype='int64', id=None),\n 'title': Value(dtype='string', id=None),\n 'text': Value(dtype='string', id=None),\n 'event_type': ClassLabel(names=['Air crash', 'Armed Conflict', 'Awards ceremony', 'Bank Robbery', 'Break historical records', 'Diplomatic Talks _ Diplomatic_Negotiation_ Summit Meeting', 'Diplomatic Visit', 'Disease Outbreaks', 'Droughts', 'Earthquakes', 'Environment Pollution', 'Famine', 'Famous Person - Commit Crime - Accuse', 'Famous Person - Commit Crime - Arrest', 'Famous Person - Commit Crime - Investigate', 'Famous Person - Commit Crime - Release', 'Famous Person - Commit Crime - Sentence', 'Famous Person - Death', 'Famous Person - Divorce', 'Famous Person - Give a speech', 'Famous Person - Marriage', 'Famous Person - Recovered', 'Famous Person - Sick', 'Financial Aid', 'Financial Crisis', 'Fire', 'Floods', 'Gas explosion', 'Government Job change - Appoint_Inauguration', 'Government Job change - Election', 'Government Job change - Resignation_Dismissal', 'Government Policy Changes', 'Hurricanes_Tornado_Storm_Blizzard', 'Insect Disaster', 'Join in an Organization', 'Mass Poisoning', 'Military Exercise', 'Mine Collapses', 'Mudslides', 'New achievements in aerospace', 'New archeological discoveries', 'New wonders in nature', 'Organization Closed', 'Organization Established', 'Organization Fine', 'Organization Merge', 'Protest_Online Condemnation', 'Regime Change', 'Riot', 'Road Crash', 'Shipwreck', 'Sign Agreement', 'Sports Competition', 'Strike', 'Tear Up Agreement', 'Train collisions', 'Tsunamis', 'Volcano Eruption', 'Withdraw from an Organization'], id=None),\n 'arguments': Value(dtype='string', id=None),\n 'date': Value(dtype='string', id=None),\n 'metadata': Value(dtype='string', id=None)}"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_dataset[\"train\"].features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "'North Korea says it will use its \"nuclear deterrent\" in response to joint US-South Korean military exercises this weekend.\\nPyongyang was ready to launch a \"retaliatory sacred war\" at any time, the state-run Korean Central News Agency (KCNA) said.\\nWashington and Seoul say the war games are to deter North Korean aggression.\\nTensions between the two Koreas have been high since the sinking of a South Korean warship in March.\\nAn international investigation said the ship was sunk by a North Korean torpedo, a claim strongly denied by Pyongyang.\\nResponding to Pyongyang\\'s warning, US State Department spokesman Philip Crowley said that Washington was \"not interested in a war of words with North Korea\". \"What we need from North Korea is fewer provocative words and more constructive action,\" the spokesman added.\\nThe BBC\\'s John Sudworth, in Seoul, says this is not the first time that North Korea has issued such a warning. Although it is likely to be dismissed as the usual diplomatic brinkmanship, the rising tension will cause concern among governments in the region, he adds.\\nThe North\\'s powerful National Defence Commission said the war games were \"nothing but outright provocations aimed to stifle the Democratic People\\'s Republic of Korea [North Korea] by force of arms,\" the KCNA reported.\\n\"The army and people of the DPRK will start a retaliatory sacred war of their own style based on nuclear deterrent any time necessary in order to counter the US imperialists and the South Korean puppet forces deliberately pushing the situation to the brink of a war,\" it added.\\nThe North had already promised a physical response to the military exercises during an Asian regional security forum in Vietnam on Friday.\\nNorth Korea\\'s delegation spokesman at the Association of South East Asian Nations (Asean) regional forum said the exercises were an example of 19th century \"gunboat diplomacy\".\\n\"It is a threat to the Korean peninsula and the region of Asia as a whole,\" he said.\\nThe forum was dominated by the crisis between the two Koreas.\\nThe war games - which begin on Sunday - will involve the aircraft carrier USS George Washington, 20 other ships and submarines, 100 aircraft and 8,000 personnel.\\nChina has criticised the plans and warned against any action which might \"exacerbate regional tensions\".\\nBut Japan is sending four military observers, in an apparent endorsement of the drills. The US announced on Wednesday that it was to impose new sanctions on North Korea, aimed at halting nuclear proliferation and the import of luxury goods.  ASEAN (Association of South East Asian Nations)\\n'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_dataset[\"train\"][0][\"text\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99db6887673e48e1a388dedcb97ca7ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jvidakovic/.cache/huggingface/datasets/csv/default-0720af0f377253e9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-a80ff54c5a9ded56.arrow\n"
     ]
    }
   ],
   "source": [
    "def preprocess_docee(examples):\n",
    "    batch_encoding = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    batch_encoding[\"labels\"] = examples[\"event_type\"]\n",
    "    return batch_encoding\n",
    "\n",
    "docee = cls_dataset.map(preprocess_docee, batched=True, remove_columns=cls_dataset[\"train\"].column_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n 'labels': Value(dtype='int64', id=None)}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docee[\"train\"].features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 1\n",
    "\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer,\n",
    "    padding=PaddingStrategy.LONGEST,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    docee[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    docee[\"validation\"],\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input_ids': torch.Size([1, 512]),\n 'attention_mask': torch.Size([1, 512]),\n 'labels': torch.Size([1])}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "\n",
    "{k: v.shape for k, v in batch.items()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.loss = tensor(3.8328, grad_fn=<NllLossBackward0>)\n",
      "outputs.logits.shape = torch.Size([1, 59])\n"
     ]
    }
   ],
   "source": [
    "# test run\n",
    "outputs = models[\"classification\"](**batch)\n",
    "print(f\"{outputs.loss = }\")\n",
    "print(f\"{outputs.logits.shape = }\")\n",
    "# moze"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "cls_optimizer = AdamW(model.parameters(), lr=5e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "17559"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=cls_optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "num_training_steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "cls_accelerator = Accelerator()\n",
    "train_dataloader, eval_dataloader, model, optimizer = cls_accelerator.prepare(\n",
    "    train_dataloader, eval_dataloader, models[\"classification\"], cls_optimizer\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d8fea9254cc4799aa1bfebac6e044e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1 = evaluate.load(\"f1\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Evaluation:   0%|          | 0/2195 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aeb28dc3775844798d0b823795a079af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.008521995382692497}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for batch in tqdm(eval_dataloader, total=len(eval_dataloader), desc=\"Evaluation\"):\n",
    "    # extract outputs\n",
    "    outputs = model(**batch)\n",
    "    # print(outputs.keys())  # loss, logits, encoder_last_hidden_state\n",
    "\n",
    "    # outputs[\"logits\"] = (BS, 59)\n",
    "    # we need argmax by dimension 1\n",
    "\n",
    "    # decode logits into labels\n",
    "    predictions = torch.argmax(outputs[\"logits\"], dim=1)\n",
    "    # print(labels)\n",
    "    f1.add_batch(\n",
    "        predictions=predictions.cpu().numpy(),\n",
    "        references=batch[\"labels\"].cpu().numpy(),\n",
    "    )\n",
    "    # break\n",
    "    # f1.add_batch(predictions=outputs[\"labels\"])\n",
    "result = f1.compute(average=\"macro\")\n",
    "print(result)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/tmp/ipykernel_32937/\u001B[0m\u001B[1;33m3052908991.py\u001B[0m:\u001B[94m1\u001B[0m in \u001B[92m<cell line: 1>\u001B[0m                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_32937/3052908991.py'\u001B[0m                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/eva\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33mluate/\u001B[0m\u001B[1;33mmodule.py\u001B[0m:\u001B[94m433\u001B[0m in \u001B[92mcompute\u001B[0m                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m430 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m431 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96many\u001B[0m(v \u001B[95mis\u001B[0m \u001B[95mnot\u001B[0m \u001B[94mNone\u001B[0m \u001B[94mfor\u001B[0m v \u001B[95min\u001B[0m inputs.values()):                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m432 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m.add_batch(**inputs)                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m433 \u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m._finalize()                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m434 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m435 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m.cache_file_name = \u001B[94mNone\u001B[0m                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m436 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m.filelock = \u001B[94mNone\u001B[0m                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/eva\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33mluate/\u001B[0m\u001B[1;33mmodule.py\u001B[0m:\u001B[94m385\u001B[0m in \u001B[92m_finalize\u001B[0m                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m382 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m383 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94melif\u001B[0m \u001B[96mself\u001B[0m.process_id == \u001B[94m0\u001B[0m:                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m384 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# Let's acquire a lock on each node files to be sure they are finished writi\u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m385 \u001B[2m│   │   │   \u001B[0mfile_paths, filelocks = \u001B[96mself\u001B[0m._get_all_cache_files()                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m386 \u001B[0m\u001B[2m│   │   │   \u001B[0m                                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m387 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# Read the predictions and references\u001B[0m                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m388 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mtry\u001B[0m:                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/eva\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33mluate/\u001B[0m\u001B[1;33mmodule.py\u001B[0m:\u001B[94m302\u001B[0m in \u001B[92m_get_all_cache_files\u001B[0m                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m299 \u001B[0m\u001B[2;33m│   │   \u001B[0m\u001B[33m\"\"\"\u001B[0m                                                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m300 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m.num_process == \u001B[94m1\u001B[0m:                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m301 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mif\u001B[0m \u001B[96mself\u001B[0m.cache_file_name \u001B[95mis\u001B[0m \u001B[94mNone\u001B[0m:                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m302 \u001B[2m│   │   │   │   \u001B[0m\u001B[94mraise\u001B[0m \u001B[96mValueError\u001B[0m(                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m303 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[33m\"\u001B[0m\u001B[33mEvaluation module cache file doesn\u001B[0m\u001B[33m'\u001B[0m\u001B[33mt exist. Please make sure that y\u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m304 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[33m\"\u001B[0m\u001B[33mat least once before calling `compute`.\u001B[0m\u001B[33m\"\u001B[0m                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m305 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m)                                                                          \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mValueError: \u001B[0mEvaluation module cache file doesn't exist. Please make sure that you call `add` or `add_batch` at \nleast once before calling `compute`.\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_32937/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3052908991.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_32937/3052908991.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/eva</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">luate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">433</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">430 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">431 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">any</span>(v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> inputs.values()):                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">432 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.add_batch(**inputs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>433 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._finalize()                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">434 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">435 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cache_file_name = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">436 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.filelock = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/eva</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">luate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">385</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_finalize</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">382 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">383 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.process_id == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">384 │   │   │   # Let's acquire a lock on each node files to be sure they are finished writi</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>385 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>file_paths, filelocks = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_all_cache_files()                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">386 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">387 │   │   │   # Read the predictions and references</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">388 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/eva</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">luate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">302</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_all_cache_files</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">299 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">300 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_process == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">301 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cache_file_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>302 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">303 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Evaluation module cache file doesn't exist. Please make sure that y</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">304 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"at least once before calling `compute`.\"</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">305 │   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Evaluation module cache file doesn't exist. Please make sure that you call `add` or `add_batch` at \nleast once before calling `compute`.\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_micro = f1.compute(average=\"micro\")\n",
    "print(f1_micro)\n",
    "# okay, so we cannot call compute multiple times"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch progress:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2755abfe796f42dbad0a6120c337dd7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 1:   0%|          | 0/17559 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0affc7d086c24e60adf435d1a564ce59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/tmp/ipykernel_7132/\u001B[0m\u001B[1;33m2302073823.py\u001B[0m:\u001B[94m11\u001B[0m in \u001B[92m<cell line: 7>\u001B[0m                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_7132/2302073823.py'\u001B[0m                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/acc\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33melerate/\u001B[0m\u001B[1;33maccelerator.py\u001B[0m:\u001B[94m1299\u001B[0m in \u001B[92mbackward\u001B[0m                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1296 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m._schedulers.append(scheduler)                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1297 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m scheduler                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1298 \u001B[0m\u001B[2m│   \u001B[0m                                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m1299 \u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mbackward\u001B[0m(\u001B[96mself\u001B[0m, loss, **kwargs):                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1300 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[33m\"\"\"\u001B[0m                                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1301 \u001B[0m\u001B[2;33m│   │   \u001B[0m\u001B[33mScales the gradients in accordance to `Accelerator.gradient_accumulation_steps` \u001B[0m  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m1302 \u001B[0m\u001B[2;33m│   │   \u001B[0m\u001B[33m`backward()` based on the configuration.\u001B[0m                                          \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mKeyboardInterrupt\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_7132/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2302073823.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 7&gt;</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_7132/2302073823.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/acc</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">elerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1299</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1296 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._schedulers.append(scheduler)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1297 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> scheduler                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1298 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1299 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, loss, **kwargs):                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1300 │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1301 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">Scales the gradients in accordance to `Accelerator.gradient_accumulation_steps` </span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1302 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">`backward()` based on the configuration.</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in tqdm(range(num_epochs), total=num_epochs, desc=\"Epoch progress\"):\n",
    "    for batch in tqdm(train_dataloader, total=len(train_dataloader), desc=f\"Epoch {epoch+1}\", leave=False):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        cls_accelerator.backward(loss)\n",
    "\n",
    "        cls_optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        cls_optimizer.zero_grad()\n",
    "\n",
    "    # eval loop\n",
    "    # model.eval()\n",
    "    # we need metrics\n",
    "    # for batch in tqdm(eval_dataloader, total=len(eval_dataloader), desc=f\"Evaluation after epoch {epoch+1}\", leave=False):\n",
    "    # what about the evaluation loop? -> stick it somewhere here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/tmp/ipykernel_7132/\u001B[0m\u001B[1;33m3734621671.py\u001B[0m:\u001B[94m1\u001B[0m in \u001B[92m<cell line: 1>\u001B[0m                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_7132/3734621671.py'\u001B[0m                         \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mNameError: \u001B[0mname \u001B[32m'print_first_param'\u001B[0m is not defined\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_7132/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3734621671.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_7132/3734621671.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'print_first_param'</span> is not defined\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_first_param(models[\"classification\"].model.encoder)\n",
    "print_first_param(models[\"summarization\"].model.encoder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'classification': {'model': BartForSequenceClassification(\n    (model): BartModel(\n      (shared): Embedding(50265, 768, padding_idx=1)\n      (encoder): BartEncoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (decoder): BartDecoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (classification_head): BartClassificationHead(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n      (out_proj): Linear(in_features=768, out_features=59, bias=True)\n    )\n  ),\n  'optimizer': None,\n  'train_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7ff3b7340a60>,\n  'eval_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7ff3b7342d70>},\n 'summarization': {'model': BartForConditionalGeneration(\n    (model): BartModel(\n      (shared): Embedding(50265, 768, padding_idx=1)\n      (encoder): BartEncoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (decoder): BartDecoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n  ),\n  'optimizer': None,\n  'train_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7ff3b7341ab0>,\n  'eval_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7ff3b7343220>}}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_epochs = 1\n",
    "cls_steps = 1  # what does this mean?\n",
    "summ_steps = 2   # what does this mean?\n",
    "\n",
    "cls_batch_size=1\n",
    "summ_batch_size=1\n",
    "\n",
    "# probably doesnt make much sense to train summarization more often than classification, right?\n",
    "# the thing is:\n",
    "#   we are actually learning SUMMARIZATION!!\n",
    "#   -> but we want to accomplish learning this summarization by utilizing classification as well\n",
    "\n",
    "cls_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=PaddingStrategy.MAX_LENGTH,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "summ_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=PaddingStrategy.MAX_LENGTH,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "tasks = {\n",
    "    \"classification\": {\n",
    "        \"model\": models[\"classification\"],\n",
    "        \"optimizer\": None,\n",
    "        \"train_dataloader\": DataLoader(\n",
    "            docee[\"train\"],\n",
    "            batch_size=cls_batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=cls_collator\n",
    "        ),\n",
    "        \"eval_dataloader\": DataLoader(\n",
    "            docee[\"validation\"],\n",
    "            batch_size=cls_batch_size,\n",
    "            collate_fn=cls_collator\n",
    "        )\n",
    "    },\n",
    "    \"summarization\": {\n",
    "        \"model\": models[\"summarization\"],\n",
    "        \"optimizer\": None,\n",
    "        \"train_dataloader\": DataLoader(\n",
    "            tokenized_cnn[\"train\"],\n",
    "            batch_size=summ_batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=summ_collator\n",
    "        ),\n",
    "        \"eval_dataloader\": DataLoader(\n",
    "            tokenized_cnn[\"validation\"],\n",
    "            batch_size=summ_batch_size,\n",
    "            collate_fn=summ_collator\n",
    "        )\n",
    "    }\n",
    "}\n",
    "\n",
    "tasks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up classification\n",
      "Setting up summarization\n"
     ]
    }
   ],
   "source": [
    "def setup_optimizers(tasks):\n",
    "    for task_name, task_objects in tasks.items():\n",
    "        print(f\"Setting up {task_name}\")\n",
    "        task_objects[\"optimizer\"] = AdamW(task_objects[\"model\"].parameters(), lr=2e-5)\n",
    "\n",
    "setup_optimizers(tasks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "{'classification': {'model': BartForSequenceClassification(\n    (model): BartModel(\n      (shared): Embedding(50265, 768, padding_idx=1)\n      (encoder): BartEncoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (decoder): BartDecoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (classification_head): BartClassificationHead(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n      (out_proj): Linear(in_features=768, out_features=59, bias=True)\n    )\n  ),\n  'optimizer': AdamW (\n  Parameter Group 0\n      amsgrad: False\n      betas: (0.9, 0.999)\n      capturable: False\n      eps: 1e-08\n      foreach: None\n      lr: 2e-05\n      maximize: False\n      weight_decay: 0.01\n  ),\n  'train_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7f1528e7b5b0>,\n  'eval_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7f151e3b71f0>},\n 'summarization': {'model': BartForConditionalGeneration(\n    (model): BartModel(\n      (shared): Embedding(50265, 768, padding_idx=1)\n      (encoder): BartEncoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (decoder): BartDecoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n  ),\n  'optimizer': AdamW (\n  Parameter Group 0\n      amsgrad: False\n      betas: (0.9, 0.999)\n      capturable: False\n      eps: 1e-08\n      foreach: None\n      lr: 2e-05\n      maximize: False\n      weight_decay: 0.01\n  ),\n  'train_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7f151e3b7f70>,\n  'eval_dataloader': <torch.utils.data.dataloader.DataLoader at 0x7f151e3b7ee0>}}"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the thing is, classification dataloader contains less examples than summarization dataloader\n",
    "# we can solve this by oversampling the classification dataloader (by using itertools.tee)\n",
    "summ_cls_ratio = len(tasks[\"summarization\"][\"train_dataloader\"]) // len(tasks[\"classification\"][\"train_dataloader\"]) + 1\n",
    "summ_cls_ratio\n",
    "# tasks[\"classification\"][\"train_dataloader\"] = tee(tasks)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import tee, chain\n",
    "\n",
    "tasks[\"classification\"][\"train_dataloader\"] = DataLoader(\n",
    "    docee[\"train\"],\n",
    "    batch_size=cls_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=cls_collator\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def set_train(tasks):\n",
    "    tasks[\"summarization\"][\"model\"].train()\n",
    "    tasks[\"classification\"][\"model\"].train()\n",
    "\n",
    "# set_train(tasks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def accelerate(tasks):\n",
    "    for task in tasks:\n",
    "        accelerator = Accelerator()\n",
    "        # tasks[task][\"accelerator\"] = Accelerator()\n",
    "        for component in [\"model\", \"optimizer\", \"train_dataloader\", \"eval_dataloader\"]:\n",
    "            tasks[task][component] = accelerator.prepare(tasks[task][component])\n",
    "        tasks[task][\"accelerator\"] = accelerator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "accelerate(tasks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "tasks[\"classification\"][\"train_dataloader\"] = chain(*tee(tasks[\"classification\"][\"train_dataloader\"], summ_cls_ratio))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[    0,  3762,     9,     5,  8260,  7749,    11,  2673,   750,     7,\n           478,     5,   382,    34, 18432,  1926,    12, 10823,  1261,     6,\n          5681,  1611,     6, 14784,    66, 11487,     8, 23285,  3980,     4,\n         50118,   500, 10338,  1780,   518,    32,  1786,     7,  7118,     5,\n           455,   913,     9,  4370,   988,     6,    61,   156, 19504,    15,\n           307,  1390,    25,    10,  4120,   237,  2130,    19, 18918, 17055,\n            36,  5714,  7203,    73,   298,    43,  2372,     4, 50118,  3750,\n           513,   411,    82,    33,    57,   848,     6,   144,     9,   106,\n            11,  1261,     4, 50118, 15852, 12434,     7,    10, 10602,  2130,\n             6,   988,    34,    57,  3022,     5,  9347, 11275,     4,  5809,\n            12, 12557,  1899,  8383,    32,   202,    11,   317,     6,     5,\n           382,   496,  4370,   824,   161,     6,     8,  1196,   420,     5,\n          3174,   382,    33,    57,  2449,     9,     5,  3348,  4854,    31,\n         21328,   476, 11723,     6,  7462, 12530,     8, 27320,  4376,     4,\n         50118,   970,    32,  4606,    13,    82,    54,  8266,  9750,  8383,\n            11,   103,     9,     5,   911,   122, 10290,     4, 50118, 36062,\n             9,  1583,     9,  1611,     8,  1252,    58,   314,   396,  4382,\n            11,  1261,     6,  3053,     8,  3090,     4, 50118, 14009,   156,\n         19504,   583,  1625,  2467,     6,  1261,     6,    23,   198,   501,\n            35,   612,    36,  1366,    35,   612,  5050,    43,    15,   307,\n             4, 50118,   243,  5546,   566,     5,   144,  2247, 16387,     7,\n           478,     5,   382,    11,  1110,     9,  2508,  2078,     8,  2003,\n         22356,  1164,     6, 10451,     7,  4370,  2224,    11,  8548,     4,\n           988,    21,    98,   670,    25,    24,  8473,    88,  1261,    14,\n            24,  2442,    10,  6874,    13,   722,    25,    24,  1410,   617,\n         18109,     6,   137,   145,   159,  9471,     7,    10, 10602,  2130,\n             4, 50118, 30872,  6379, 18420,  5000,  2037,   171,    30,  2755,\n             6,  1712,     5,  2130,   423, 12434,     4, 50118,  9685, 33834,\n          3279,  5794,    11,     5,  4602,     9,  1625, 21124,    12, 18716,\n             5,  2130,    31,    10, 10602,  6943,    15,   395,     4, 50118,\n          4148,   294,    24,    21,   202,    10,  4120,    80,  6874,    53,\n            30,   307,   662,    24,    56,  1348, 37433,  4120,   292,     6,\n             5,  1609,   672,     4, 50118, 31614,   503,   224,    23,   513,\n           237,    82,   962,    25,    10,   898,     9,     5,  2130,    11,\n           272,  7842,  3898,   413,     4, 50118,  1121, 22142,  4104,   413,\n             6,  3090,     6,    10,  4204,   512,    12,    29,  4393,  1334,\n          4639,    30,    10,  9346,     9,  2508,   478,    10,  1830,   184,\n             6,  2429,    10,  1816,     9,   365,     4,   178,    10,   313,\n           962,    77,    10,  3907,  1064,    15,    39,   512,   583,  5420,\n             6,   369,  1961,    15,   296,     4, 50118, 14009,   656,  2288,\n           848,    23,   513,   508,    82,    25,    24,  1595,   149,  1505,\n           730,    35,   411,    11, 18207,     6,   237,    11, 25687,     8,\n           130,    11,  1448, 14254,     4, 50118,   133,  2130,    34,  6536,\n            66,   476,     7,    55,    87, 10742,     6,   151,  1611,     8,\n          1252,     4, 50118,  9690,    87, 27173,     6,   151,    82,    11,\n          1261,    58,  2740,     7, 15013,    53,   503,   679,   171,  8266,\n             5,  2892,     4, 50118,   133,  8095,   343,     9,  8712, 45551,\n           636,  3019,   431,    10,  2130,  6564,     9,   823,   290,  2543,\n            36,   176,     4,   245,   119,   322, 50118,   113,   970,    32,\n            98,   171, 21328,   476,  2301,     8,  3980,    14,    24,    18,\n           818,  4703,     7,   120,   149,     5,   343,    60,   400,  3647,\n          3415,     2]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([32], device='cuda:0')}"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_iter = iter(tasks[\"classification\"][\"train_dataloader\"])\n",
    "batch = next(test_iter)\n",
    "batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def setup_dataloader_lengths(tasks):\n",
    "    tasks[\"classification\"][\"train_len\"] = len(docee[\"train\"]) // cls_batch_size\n",
    "    tasks[\"summarization\"][\"train_len\"] = len(tasks[\"summarization\"][\"train_dataloader\"])\n",
    "\n",
    "setup_dataloader_lengths(tasks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "def setup_schedulers(tasks):\n",
    "    for task in tasks:\n",
    "        tasks[task][\"lr_scheduler\"] = get_scheduler(\n",
    "            \"linear\",\n",
    "            tasks[task][\"optimizer\"],\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=num_epochs * tasks[task][\"train_len\"]\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "{'classification': {'model': BartForSequenceClassification(\n    (model): BartModel(\n      (shared): Embedding(50265, 768, padding_idx=1)\n      (encoder): BartEncoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (decoder): BartDecoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (classification_head): BartClassificationHead(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (dropout): Dropout(p=0.0, inplace=False)\n      (out_proj): Linear(in_features=768, out_features=59, bias=True)\n    )\n  ),\n  'optimizer': AcceleratedOptimizer (\n  Parameter Group 0\n      amsgrad: False\n      betas: (0.9, 0.999)\n      capturable: False\n      eps: 1e-08\n      foreach: None\n      initial_lr: 2e-05\n      lr: 2e-05\n      maximize: False\n      weight_decay: 0.01\n  ),\n  'train_dataloader': <itertools.chain at 0x7ff3a76f77f0>,\n  'eval_dataloader': <accelerate.data_loader.DataLoaderShard at 0x7ff3a5e38f70>,\n  'accelerator': <accelerate.accelerator.Accelerator at 0x7ff3a5e38b20>,\n  'train_len': 17559,\n  'lr_scheduler': <torch.optim.lr_scheduler.LambdaLR at 0x7ff3a64f0e80>},\n 'summarization': {'model': BartForConditionalGeneration(\n    (model): BartModel(\n      (shared): Embedding(50265, 768, padding_idx=1)\n      (encoder): BartEncoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartEncoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (activation_fn): GELUActivation()\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (decoder): BartDecoder(\n        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n        (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n        (layers): ModuleList(\n          (0): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (1): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (2): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (3): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (4): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n          (5): BartDecoderLayer(\n            (self_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (activation_fn): GELUActivation()\n            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): BartAttention(\n              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n  ),\n  'optimizer': AcceleratedOptimizer (\n  Parameter Group 0\n      amsgrad: False\n      betas: (0.9, 0.999)\n      capturable: False\n      eps: 1e-08\n      foreach: None\n      initial_lr: 2e-05\n      lr: 2e-05\n      maximize: False\n      weight_decay: 0.01\n  ),\n  'train_dataloader': <accelerate.data_loader.DataLoaderShard at 0x7ff3a76f7280>,\n  'eval_dataloader': <accelerate.data_loader.DataLoaderShard at 0x7ff3a76f49d0>,\n  'accelerator': <accelerate.accelerator.Accelerator at 0x7ff480f5fbe0>,\n  'train_len': 287113,\n  'lr_scheduler': <torch.optim.lr_scheduler.LambdaLR at 0x7ff3b4a359f0>}}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_schedulers(tasks)\n",
    "tasks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "set_train(tasks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6686064ee274d22b6d900e795f13bdf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "classification progress:   0%|          | 0/17559 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7b86f100c274399b9be22a73844a655"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "summarization progress:   0%|          | 0/287113 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac593c00b66a4f0baa95991914c4a2f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[31m╭─\u001B[0m\u001B[31m──────────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m───────────────────────────────\u001B[0m\u001B[31m─╮\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/tmp/ipykernel_44938/\u001B[0m\u001B[1;33m3321027768.py\u001B[0m:\u001B[94m18\u001B[0m in \u001B[92m<cell line: 1>\u001B[0m                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_44938/3321027768.py'\u001B[0m                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33mch/optim/\u001B[0m\u001B[1;33mlr_scheduler.py\u001B[0m:\u001B[94m65\u001B[0m in \u001B[92mwrapper\u001B[0m                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  62 \u001B[0m\u001B[2m│   │   │   │   \u001B[0minstance = instance_ref()                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  63 \u001B[0m\u001B[2m│   │   │   │   \u001B[0minstance._step_count += \u001B[94m1\u001B[0m                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  64 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mwrapped = func.\u001B[92m__get__\u001B[0m(instance, \u001B[96mcls\u001B[0m)                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m  65 \u001B[2m│   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m wrapped(*args, **kwargs)                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  66 \u001B[0m\u001B[2m│   │   │   \u001B[0m                                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  67 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# Note that the returned function here is no longer a bound method,\u001B[0m           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  68 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# so attributes like `__func__` and `__self__` no longer exist.\u001B[0m               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/acc\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33melerate/\u001B[0m\u001B[1;33moptimizer.py\u001B[0m:\u001B[94m140\u001B[0m in \u001B[92mstep\u001B[0m                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m137 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[2m# If we reduced the loss scale, it means the optimizer step was skipped \u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m138 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[96mself\u001B[0m._is_overflow = scale_after < scale_before                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m139 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m140 \u001B[2m│   │   │   │   \u001B[0m\u001B[96mself\u001B[0m.optimizer.step(closure)                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m141 \u001B[0m\u001B[2m│   \u001B[0m                                                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m142 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92m_switch_parameters\u001B[0m(\u001B[96mself\u001B[0m, parameters_map):                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m143 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mfor\u001B[0m param_group \u001B[95min\u001B[0m \u001B[96mself\u001B[0m.optimizer.param_groups:                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33mch/optim/\u001B[0m\u001B[1;33mlr_scheduler.py\u001B[0m:\u001B[94m65\u001B[0m in \u001B[92mwrapper\u001B[0m                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  62 \u001B[0m\u001B[2m│   │   │   │   \u001B[0minstance = instance_ref()                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  63 \u001B[0m\u001B[2m│   │   │   │   \u001B[0minstance._step_count += \u001B[94m1\u001B[0m                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  64 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mwrapped = func.\u001B[92m__get__\u001B[0m(instance, \u001B[96mcls\u001B[0m)                                     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m  65 \u001B[2m│   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m wrapped(*args, **kwargs)                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  66 \u001B[0m\u001B[2m│   │   │   \u001B[0m                                                                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  67 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# Note that the returned function here is no longer a bound method,\u001B[0m           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m  68 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# so attributes like `__func__` and `__self__` no longer exist.\u001B[0m               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/acc\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33melerate/\u001B[0m\u001B[1;33moptimizer.py\u001B[0m:\u001B[94m140\u001B[0m in \u001B[92mstep\u001B[0m                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m137 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[2m# If we reduced the loss scale, it means the optimizer step was skipped \u001B[0m   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m138 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[96mself\u001B[0m._is_overflow = scale_after < scale_before                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m139 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m140 \u001B[2m│   │   │   │   \u001B[0m\u001B[96mself\u001B[0m.optimizer.step(closure)                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m141 \u001B[0m\u001B[2m│   \u001B[0m                                                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m142 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92m_switch_parameters\u001B[0m(\u001B[96mself\u001B[0m, parameters_map):                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m143 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mfor\u001B[0m param_group \u001B[95min\u001B[0m \u001B[96mself\u001B[0m.optimizer.param_groups:                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33mch/optim/\u001B[0m\u001B[1;33moptimizer.py\u001B[0m:\u001B[94m113\u001B[0m in \u001B[92mwrapper\u001B[0m                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m110 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mobj, *_ = args                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m111 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mprofile_name = \u001B[33m\"\u001B[0m\u001B[33mOptimizer.step#\u001B[0m\u001B[33m{}\u001B[0m\u001B[33m.step\u001B[0m\u001B[33m\"\u001B[0m.format(obj.\u001B[91m__class__\u001B[0m.\u001B[91m__name__\u001B[0m)     \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m112 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mwith\u001B[0m torch.autograd.profiler.record_function(profile_name):                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m113 \u001B[2m│   │   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m func(*args, **kwargs)                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m114 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mreturn\u001B[0m wrapper                                                                 \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m115 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m116 \u001B[0m\u001B[2m│   │   \u001B[0mhooked = \u001B[96mgetattr\u001B[0m(\u001B[96mself\u001B[0m.\u001B[91m__class__\u001B[0m.step, \u001B[33m\"\u001B[0m\u001B[33mhooked\u001B[0m\u001B[33m\"\u001B[0m, \u001B[94mNone\u001B[0m)                              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33mch/autograd/\u001B[0m\u001B[1;33mgrad_mode.py\u001B[0m:\u001B[94m27\u001B[0m in \u001B[92mdecorate_context\u001B[0m                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 24 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[1;95m@functools\u001B[0m.wraps(func)                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 25 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92mdecorate_context\u001B[0m(*args, **kwargs):                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 26 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mwith\u001B[0m \u001B[96mself\u001B[0m.clone():                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m 27 \u001B[2m│   │   │   │   \u001B[0m\u001B[94mreturn\u001B[0m func(*args, **kwargs)                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 28 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m cast(F, decorate_context)                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 29 \u001B[0m\u001B[2m│   \u001B[0m                                                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m 30 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m \u001B[92m_wrap_generator\u001B[0m(\u001B[96mself\u001B[0m, func):                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33mch/optim/\u001B[0m\u001B[1;33madamw.py\u001B[0m:\u001B[94m161\u001B[0m in \u001B[92mstep\u001B[0m                                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m158 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m159 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mstate_steps.append(state[\u001B[33m'\u001B[0m\u001B[33mstep\u001B[0m\u001B[33m'\u001B[0m])                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m160 \u001B[0m\u001B[2m│   │   │   \u001B[0m                                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m161 \u001B[2m│   │   │   \u001B[0madamw(params_with_grad,                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m162 \u001B[0m\u001B[2m│   │   │   │     \u001B[0mgrads,                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m163 \u001B[0m\u001B[2m│   │   │   │     \u001B[0mexp_avgs,                                                                \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m164 \u001B[0m\u001B[2m│   │   │   │     \u001B[0mexp_avg_sqs,                                                             \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33mch/optim/\u001B[0m\u001B[1;33madamw.py\u001B[0m:\u001B[94m218\u001B[0m in \u001B[92madamw\u001B[0m                                                                   \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m215 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94melse\u001B[0m:                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m216 \u001B[0m\u001B[2m│   │   \u001B[0mfunc = _single_tensor_adamw                                                        \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m217 \u001B[0m\u001B[2m│   \u001B[0m                                                                                       \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m218 \u001B[2m│   \u001B[0mfunc(params,                                                                           \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m219 \u001B[0m\u001B[2m│   │    \u001B[0mgrads,                                                                            \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m220 \u001B[0m\u001B[2m│   │    \u001B[0mexp_avgs,                                                                         \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m221 \u001B[0m\u001B[2m│   │    \u001B[0mexp_avg_sqs,                                                                      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33m/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor\u001B[0m \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[2;33mch/optim/\u001B[0m\u001B[1;33madamw.py\u001B[0m:\u001B[94m309\u001B[0m in \u001B[92m_single_tensor_adamw\u001B[0m                                                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m                                                                                                  \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m306 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[2m# Use the max. for normalizing running avg. of gradient\u001B[0m                    \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m307 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mdenom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)      \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m308 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94melse\u001B[0m:                                                                          \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m \u001B[31m❱ \u001B[0m309 \u001B[2m│   │   │   │   \u001B[0mdenom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)              \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m310 \u001B[0m\u001B[2m│   │   │   \u001B[0m                                                                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m311 \u001B[0m\u001B[2m│   │   │   \u001B[0mparam.addcdiv_(exp_avg, denom, value=-step_size)                               \u001B[31m│\u001B[0m\n\u001B[31m│\u001B[0m   \u001B[2m312 \u001B[0m                                                                                           \u001B[31m│\u001B[0m\n\u001B[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001B[0m\n\u001B[1;91mKeyboardInterrupt\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_44938/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3321027768.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">18</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_44938/3321027768.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lr_scheduler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">65</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  62 │   │   │   │   </span>instance = instance_ref()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  63 │   │   │   │   </span>instance._step_count += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  64 │   │   │   │   </span>wrapped = func.<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__get__</span>(instance, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  65 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapped(*args, **kwargs)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  66 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  67 │   │   │   # Note that the returned function here is no longer a bound method,</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  68 │   │   │   # so attributes like `__func__` and `__self__` no longer exist.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/acc</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">elerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">140</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   │   │   │   # If we reduced the loss scale, it means the optimizer step was skipped </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._is_overflow = scale_after &lt; scale_before                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>140 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.step(closure)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_switch_parameters</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, parameters_map):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> param_group <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.param_groups:                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">lr_scheduler.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">65</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  62 │   │   │   │   </span>instance = instance_ref()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  63 │   │   │   │   </span>instance._step_count += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  64 │   │   │   │   </span>wrapped = func.<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__get__</span>(instance, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>  65 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapped(*args, **kwargs)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  66 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  67 │   │   │   # Note that the returned function here is no longer a bound method,</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  68 │   │   │   # so attributes like `__func__` and `__self__` no longer exist.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/acc</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">elerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">140</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   │   │   │   # If we reduced the loss scale, it means the optimizer step was skipped </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._is_overflow = scale_after &lt; scale_before                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>140 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.step(closure)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_switch_parameters</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, parameters_map):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> param_group <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.optimizer.param_groups:                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">optimizer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">113</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 │   │   │   │   </span>obj, *_ = args                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   │   │   </span>profile_name = <span style=\"color: #808000; text-decoration-color: #808000\">\"Optimizer.step#{}.step\"</span>.format(obj.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>)     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.autograd.profiler.record_function(profile_name):                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>113 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> wrapper                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   │   </span>hooked = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.step, <span style=\"color: #808000; text-decoration-color: #808000\">\"hooked\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">grad_mode.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">27</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 25 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_context</span>(*args, **kwargs):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 26 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.clone():                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 27 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 28 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cast(F, decorate_context)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 29 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 30 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrap_generator</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, func):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">adamw.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">161</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">step</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 │   │   │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 │   │   │   │   </span>state_steps.append(state[<span style=\"color: #808000; text-decoration-color: #808000\">'step'</span>])                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>161 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>adamw(params_with_grad,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   │   │     </span>grads,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   │   │   │     </span>exp_avgs,                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   │   │   │     </span>exp_avg_sqs,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">adamw.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">218</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">adamw</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 │   │   </span>func = _single_tensor_adamw                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">217 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>218 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>func(params,                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">219 │   │    </span>grads,                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 │   │    </span>exp_avgs,                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">221 │   │    </span>exp_avg_sqs,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/jvidakovic/anaconda3/envs/cross_lingual_data_augmentation/lib/python3.10/site-packages/tor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">ch/optim/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">adamw.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">309</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_single_tensor_adamw</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">306 │   │   │   │   # Use the max. for normalizing running avg. of gradient</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">307 │   │   │   │   </span>denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">308 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>309 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">310 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">311 │   │   │   </span>param.addcdiv_(exp_avg, denom, value=-step_size)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">312 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs), desc=\"Epoch\", total=num_epochs):\n",
    "    # load training data, step by step\n",
    "    num_epoch_steps = len(tasks[\"summarization\"][\"train_dataloader\"]) * 2\n",
    "    iters = {task: iter(tasks[task][\"train_dataloader\"]) for task in tasks}\n",
    "    progress_bars = {\n",
    "        task: tqdm(range(tasks[task][\"train_len\"]), desc=f\"{task} progress\", total=tasks[task][\"train_len\"], leave=False)\n",
    "        for task in tasks\n",
    "    }\n",
    "    for step in range(num_epoch_steps):\n",
    "        if step % 2 == 0: # train summarization\n",
    "            task = \"summarization\"\n",
    "        else:\n",
    "            task = \"classification\"\n",
    "        batch = next(iters[task])\n",
    "        outputs = tasks[task][\"model\"](**batch)\n",
    "        loss = outputs.loss\n",
    "        tasks[task][\"accelerator\"].backward(loss)\n",
    "        tasks[task][\"optimizer\"].step()\n",
    "        tasks[task][\"lr_scheduler\"].step()\n",
    "        tasks[task][\"optimizer\"].zero_grad()\n",
    "        progress_bars[task].update(1)\n",
    "\n",
    "# pa ovo radi buraz\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
