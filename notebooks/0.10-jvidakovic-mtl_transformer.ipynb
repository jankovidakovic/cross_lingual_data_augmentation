{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import BartForSequenceClassification, BartForConditionalGeneration\n",
    "\n",
    "PRETRAINED_MODEL_NAME_OR_PATH=\"ainize/bart-base-cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def setup_models():\n",
    "    # initialize models\n",
    "    classification_model = BartForSequenceClassification.from_pretrained(PRETRAINED_MODEL_NAME_OR_PATH)\n",
    "    summarization_model = BartForConditionalGeneration.from_pretrained(PRETRAINED_MODEL_NAME_OR_PATH)\n",
    "\n",
    "    # share parameters\n",
    "    summarization_model.model.shared = classification_model.model.shared\n",
    "    summarization_model.model.encoder = classification_model.model.encoder\n",
    "    summarization_model.model.decoder = classification_model.model.decoder\n",
    "\n",
    "    return {\n",
    "        \"summarization\": summarization_model,\n",
    "        \"classification\": classification_model\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ainize/bart-base-cnn were not used when initializing BartForSequenceClassification: ['final_logits_bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at ainize/bart-base-cnn and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.weight', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "models = setup_models()\n",
    "assert id(models[\"summarization\"].model.shared) == id(models[\"classification\"].model.shared)\n",
    "assert id(models[\"summarization\"].model.encoder) == id(models[\"classification\"].model.encoder)\n",
    "assert id(models[\"summarization\"].model.decoder) == id(models[\"classification\"].model.decoder)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# we need a:\n",
    "#   -> dataframe loaded with docee examples\n",
    "#   -> tokenizer (bart tokenizer)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_NAME_OR_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/home/jvidakovic/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "text/plain": "13368"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# bruhus\n",
    "summ_dataset = load_dataset(\"cnn_dailymail\", name=\"3.0.0\", split=\"validation\")\n",
    "len(summ_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'article': '(CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don\\'t know, but the fact that so many people can have a life extension, that\\'s pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for all the support and prayers,\" a comment on a Facebook page in her name read. \"I know this entire journey is much bigger than all of us. I also know I\\'m just the messenger.\" CNN cannot verify the authenticity of the page. But the power that multiplied Broussard\\'s gift was data processing of genetic profiles from donor-recipient pairs. It works on a simple swapping principle but takes it to a much higher level, according to California Pacific Medical Center in San Francisco. So high, that it is taking five surgeons, a covey of physician assistants, nurses and anesthesiologists, and more than 40 support staff to perform surgeries on 12 people. They are extracting six kidneys from donors and implanting them into six recipients. \"The ages of the donors and recipients range from 26 to 70 and include three parent and child pairs, one sibling pair and one brother and sister-in-law pair,\" the medical center said in a statement. The chain of surgeries is to be wrapped up Friday. In late March, the medical center is planning to hold a reception for all 12 patients. Here\\'s how the super swap works, according to California Pacific Medical Center. Say, your brother needs a kidney to save his life, or at least get off of dialysis, and you\\'re willing to give him one of yours. But then it turns out that your kidney is not a match for him, and it\\'s certain his body would reject it. Your brother can then get on a years-long waiting list for a kidney coming from an organ donor who died. Maybe that will work out -- or not, and time could run out for him. Alternatively, you and your brother could look for another recipient-living donor couple like yourselves -- say, two more siblings, where the donor\\'s kidney isn\\'t suited for his sister, the recipient. But maybe your kidney is a match for his sister, and his kidney is a match for your brother. So, you\\'d do a swap. That\\'s called a paired donation. It\\'s a bit of a surgical square dance, where four people cross over partners temporarily and everybody goes home smiling. But instead of a square dance, Broussard\\'s generous move set off a chain reaction, like dominoes falling. Her kidney, which was removed Thursday, went to a recipient, who was paired with a donor. That donor\\'s kidney went to the next recipient, who was also paired with a donor, and so on. On Friday, the last donor will give a kidney to someone who has been biding time on one of those deceased donor lists to complete the chain. Such long-chain transplanting is rare. It\\'s been done before, California Pacific Medical Center said in a statement, but matching up the people in the chain has been laborious and taken a long time. That changed when a computer programmer named David Jacobs received a kidney transplant. He had been waiting on a deceased donor list, when a live donor came along -- someone nice enough to give away a kidney to a stranger. Jacobs paid it forward with his programming skills, creating MatchGrid, a program that genetically matches up donor pairs or chains quickly. \"When we did a five-way swap a few years ago, which was one of the largest, it took about three to four months. We did this in about three weeks,\" Jacobs said. But this chain wouldn\\'t have worked so quickly without Broussard\\'s generosity -- or may not have worked at all. \"The significance of the altruistic donor is that it opens up possibilities for pairing compatible donors and recipients,\" said Dr. Steven Katznelson. \"Where there had been only three or four options, with the inclusion of the altruistic donor, we had 140 options to consider for matching donors and recipients.\" And that\\'s divine, Broussard\\'s friend Shirley Williams wrote in a comment her on Broussard\\'s Facebook page. \"You are a true angel my friend.\"',\n 'highlights': 'Zully Broussard decided to give a kidney to a stranger .\\nA new computer program helped her donation spur transplants for six kidney patients .',\n 'id': 'a4942dd663020ca54575471657a0af38d82897d6'}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ_dataset[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['article', 'highlights', 'id', 'input_ids', 'attention_mask'])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# obtain a random batch\n",
    "batch = summ_dataset[:8]\n",
    "batch.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def compose2(f, g):\n",
    "    def composition(*args, **kwargs):\n",
    "        g_output = g(*args, **kwargs)\n",
    "        return f(g_output)\n",
    "    return composition\n",
    "\n",
    "def c(*fs):\n",
    "    def composition(*args, **kwargs):\n",
    "        output = fs[-1](*args, **kwargs)\n",
    "        for f in reversed(fs[:-1]):\n",
    "            output = f(output)\n",
    "        return output\n",
    "    return composition\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0720af0f377253e9\n",
      "Found cached dataset csv (/home/jvidakovic/.cache/huggingface/datasets/csv/default-0720af0f377253e9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c73a1809afea46f5b50e2f1a7b283c8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['index', 'title', 'text', 'event_type', 'arguments', 'date', 'metadata'],\n        num_rows: 17559\n    })\n    validation: Dataset({\n        features: ['index', 'title', 'text', 'event_type', 'arguments', 'date', 'metadata'],\n        num_rows: 2195\n    })\n})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# okay, we got this\n",
    "# cls_dataset = load_dataset(\"csv\", data_files=\"../data/docee/train_all.csv\")\n",
    "# data_files can be a dictionary, where key is the name of the split, and value is path to the split\n",
    "cls_dataset = load_dataset(\"csv\", data_files={\n",
    "    \"train\": \"../data/docee/18091999/train.csv\",\n",
    "    \"validation\": \"../data/docee/18091999/early_stopping.csv\"\n",
    "})\n",
    "cls_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/jvidakovic/.cache/huggingface/datasets/csv/default-0720af0f377253e9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-1b432e07d6b975f8.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'index': [8677, 13606, 10423],\n 'title': ['Simulation of glacial calving and tsunami waves predicts climate change consequences',\n  'Four protesters and two police officers are killed during clashes in Baghdad.',\n  'Italian firm Fiat Chrysler  proposes a merger with French carmaker Renault. The new company will be based in the Netherlands and will be listed on the Milan, Paris and New York stock exchanges.'],\n 'text': ['As natural disasters intensify due to climate change, accurate predictions of weather patterns and mechanisms are greatly needed to mitigate damage. Coastal regions will be the most affected by changing weather, with events such as tsunamis and hurricanes becoming more frequent and life-threatening. While most tsunamis are caused by earthquakes and tectonic activity, the warming of the planet is now increasing the occurrence of tsunamis caused by glacier calving, when chunks of glacier break off and become icebergs. Additionally, glacier calving is predicted to be the main contributor to sea level rise in the near future. Now, researchers at the School of Engineering and Applied Science have created a computer model that can accurately simulate those dynamics. In a new study, published in the recently established journal Nature Communications Earth & Environment, Penn engineers describe a new simulation that models three key aspects: the ice fracture mechanics within the glacier, the fluid dynamics of the surrounding ocean water, and the interaction between the two. The researchers employed a technique known as the material point method (MPM) which is used for a simulating the interactions between matter of different phases. Their study shows that this technique is capable of accurately describing glacial calving and resulting tsunami waves. By demonstrating their model’s predictive capabilities, the researchers are refining the empirical calving laws used in large-scale earth-system models, as well as improving hazard assessments and mitigation measures in coastal regions, which are essential in the context of climate change. The study was led by Joshuah Wolper, then a graduate student in Penn Engineering’s Department of Computer and Information Sciences (CIS) and current postdoctoral fellow in Mechanical Engineering and Applied Mechanics (MEAM), Chenfanfu Jiang, then assistant professor in CIS, now an assistant professor in the Department of Mathematics at UCLA, and Professor Johan Gaume, head of SLAB, the EPFL Snow and Avalanche Simulation Laboratory in Switzerland. This story is by Melissa Pappas. Read more at Penn Engineering Today.   ',\n  'BAGHDAD (Reuters) - Six Iraqis including two police officers were killed and scores were wounded in Baghdad and other cities on Monday in clashes with security forces, medical and security sources said, as anti-government unrest resumed after a lull of several weeks.\\nThree protesters succumbed to their wounds at a Baghdad hospital after police fired live rounds in Tayaran Square, the sources said. Two protesters were shot by live bullets while a third was hit by a tear gas canister, they said.\\nA fourth demonstrator was shot dead by police in the Shi’ite holy city of Kerbala, the sources added.\\nProtesters threw petrol bombs and stones at police who responded with tear gas and stun grenades, Reuters witnesses said.\\n“They (security forces) should stop shooting and aiming, who are they and who are we? Both sides are Iraqis. So why are you killing your brothers?” said one woman protester in Baghdad who declined to give her name.\\nThree Katyusha rockets fell inside the capital’s heavily fortified Green Zone which houses government buildings and foreign missions, police sources told Reuters. The rockets were launched from Zafaraniyah district outside Baghdad, the sources said, adding that two rockets landed near the U.S. embassy.\\nIn the Iraqi oil city of Basra, two policemen were struck and killed by a civilian car during a protest, security sources said. The driver was trying to avoid the scene of clashes between protesters and security forces when he drove into the two officers, they said.\\nElsewhere in southern Iraq, hundreds of protesters burned tires and blocked main roads in several cities, including Nassiriya, Kerbala and Amara. They say Prime Minister Adel Abdul Mahdi has not fulfilled promises including naming a new government acceptable to Iraqis.\\nBaghdad police said its forces had reopened all roads that were closed by “violent gatherings”. It said 14 officers were wounded near Tahrir square, including some with head wounds and broken bones.\\nTraffic was disrupted on a highway linking Baghdad to southern cities, a Reuters witness said. Production in southern oilfields was unaffected by the unrest, oil officials said.\\nMass protests have gripped Iraq since Oct. 1, with mostly young protesters demanding an overhaul of a political system they see as profoundly corrupt and as keeping most Iraqis in poverty. More than 450 people have been killed.\\nNumbers had dwindled but protests resumed last week as demonstrators sought to keep up momentum after attention turned to the threat of a U.S.-Iran conflict following Washington’s killing of Tehran’s top general in an air strike inside Iraq.\\nThe killing of Qassem Soleimani, to which Tehran responded with a ballistic missile attack on two Iraqi military bases housing U.S. troops, has highlighted the influence of some foreign powers in Iraq, especially Iran and the United States.\\n',\n  'Fiat Chrysler has made a \"transformative\" merger proposal for French carmaker Renault, the Italian firm said on Monday. The combined business would be 50% owned by Fiat shareholders and 50% by Renault stockholders.\\nThe carmaker said the merger would create a global automotive leader, with 8.7 million vehicle sales.\\nCarmakers have faced pressure to consolidate amid major industry shifts, including towards electric vehicles. Shares in both companies rose strongly following the announcement.\\nIn a statement, Fiat Chrysler (FCA) said the planned merger would create a \"world leader in the rapidly changing automotive industry with a strong position in transforming technologies, including electrification and autonomous driving\". Fiat said that if the firms\\' 2018 financial results were totted up, the combined company\\'s annual revenues would be nearly €170bn (£149.6bn; $190.5bn), with operating profit of more than €10bn and net profit of more than €8bn. No plant closures would be caused as a result of the tie-up, the carmaker said. It will aim to save €5bn a year by sharing development costs on technology such as electric vehicles and self-driving cars. It is thought some managerial positions may be lost, but the companies will be keen to show that production-line jobs are being preserved.\\nThe new company will be based in the Netherlands and will be listed on the Milan, Paris and New York stock exchanges.\\nTo make the merger one of equals, the slightly-wealthier FCA will pay a special dividend of €2.5bn and sell its Comau robotics business.\\nThe proposal will be considered by the Renault board. Who will lead the new entity and what it might be called are not yet decided.\\nIf the plan goes ahead, Nissan and the French government will own about 7.5% apiece of the new, merged company.\\nThe French government favours the merger but wants more details before giving its final approval, a spokeswoman said. The Italian government may want to acquire a share of the new firm to balance France\\'s stake, said a politician from the Northern League, the country\\'s largest party, according to Reuters.\\nBy sales, the new company will be number four in North America, number two in the region which covers Europe, the Middle East and Africa and the biggest in Latin America.\\nIndustry shifts toward electric models, along with stricter emissions standards and the development of new technologies for autonomous vehicles, have put increasing pressure on carmakers to consolidate. Renault already has an alliance with Japan\\'s Nissan, in which research costs and parts are shared. The companies own shares in each other, too. Renault owns 43.4% of Nissan\\'s shares and Nissan owns 15% of Renault. The former chief executive of both Nissan and Renault, Carlos Ghosn, is awaiting trial following his fourth arrest amid allegations of financial misconduct. The allegations have put a strain on the 20-year-old alliance, which also includes Japan\\'s Mitsubishi Motors.\\nNew entrants in the motoring sector such as Tesla, as well as cash-rich companies developing driverless technology such as Amazon and Google-owned Waymo, are putting pressure on older and often heavily indebted carmakers to keep up. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'],\n 'event_type': ['Tsunamis',\n  'Protest_Online Condemnation',\n  'Organization Merge'],\n 'arguments': [\"[{'start': 335, 'end': 367, 'type': 'Causes', 'text': 'earthquakes and tectonic activity'}, {'start': 370, 'end': 394, 'type': 'Causes', 'text': 'the warming of the planet'}, {'start': 635, 'end': 694, 'type': 'People/Organization who predicted the disaster', 'text': 'researchers at the School of Engineering and Applied Science'}]\",\n  \"[{'start': 20, 'end': 95, 'type': 'Casualties and Losses', 'text': 'Six Iraqis including two police officers were killed and scores were wounded'}, {'start': 100, 'end': 123, 'type': 'Location', 'text': 'Baghdad and other cities'}, {'start': 128, 'end': 133, 'type': 'Date', 'text': 'Monday'}, {'start': 268, 'end': 282, 'type': 'Casualties and Losses', 'text': 'Three protester'}, {'start': 367, 'end': 380, 'type': 'Location', 'text': 'Tayaran Square'}]\",\n  \"[{'start': 0, 'end': 12, 'type': 'Acquiree', 'text': 'Fiat Chrysler'}, {'start': 69, 'end': 76, 'type': 'The industry in which the organization operates', 'text': 'carmaker'}, {'start': 78, 'end': 84, 'type': 'Acquiree', 'text': 'Renault'}, {'start': 112, 'end': 117, 'type': 'Date', 'text': 'Monday'}, {'start': 164, 'end': 167, 'type': 'The leader of the merged organization', 'text': 'Fiat'}, {'start': 193, 'end': 199, 'type': 'The leader of the merged organization', 'text': 'Renault'}]\"],\n 'date': [None, 'January 2020', 'May 2019'],\n 'metadata': [None, \"['(Reuters)']\", \"['(BBC)']\"]}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_dataset[\"train\"].shuffle(42).select(range(100))[:3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from transformers.utils import PaddingStrategy\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 100\n",
    "\n",
    "def process_summary_example(examples):\n",
    "    # tokenize the article\n",
    "    batch_encoding = tokenizer(\n",
    "        examples[\"article\"],\n",
    "        max_length=max_input_length,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # tokenize the labels\n",
    "    tokenized_highlights = tokenizer(\n",
    "        examples[\"highlights\"],\n",
    "        max_length=max_target_length,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    batch_encoding[\"labels\"] = tokenized_highlights[\"input_ids\"]\n",
    "    return batch_encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/14 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2bf54bf56074cd88302d1596e283029"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_cnn = summ_dataset.map(process_summary_example, batched=True, remove_columns=[\"id\", \"article\", \"highlights\"])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'article': Value(dtype='string', id=None),\n 'highlights': Value(dtype='string', id=None),\n 'id': Value(dtype='string', id=None),\n 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_cnn.features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d920e4cdc1f4fa58476da05e7c70687"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'rouge1': 0.923076923076923,\n 'rouge2': 0.7272727272727272,\n 'rougeL': 0.923076923076923,\n 'rougeLsum': 0.923076923076923}"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "#import evaluate\n",
    "rouge_score = evaluate.load(\"rouge\")\n",
    "\n",
    "generated_summary = \"I absolutely loved reading the Hunger Games\"\n",
    "reference_summary = \"I loved reading the Hunger Games\"\n",
    "\n",
    "scores = rouge_score.compute(\n",
    "    predictions=[generated_summary],\n",
    "    references=[reference_summary]\n",
    ")\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 1\n",
    "num_train_epochs = 1\n",
    "logging_steps = len(summ_dataset) // batch_size\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{PRETRAINED_MODEL_NAME_OR_PATH}-finetuned-cnn\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=True,\n",
    "    sortish_sampler=True,\n",
    "    generation_max_length=150,\n",
    "    generation_num_beams=1\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # Compute ROUGE scores\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract the median scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "summ_data_collator = DataCollatorForSeq2Seq(tokenizer, model=models[\"summarization\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'input_ids': [0,\n   1640,\n   16256,\n   43,\n   11957,\n   6,\n   8,\n   110,\n   4085,\n   40,\n   28,\n   39582,\n   4,\n   280,\n   189,\n   2369,\n   101,\n   41,\n   43962,\n   2329,\n   1580,\n   6,\n   53,\n   77,\n   525,\n   19678,\n   163,\n   8508,\n   7485,\n   1120,\n   1403,\n   12445,\n   1276,\n   7,\n   492,\n   65,\n   9,\n   69,\n   33473,\n   7,\n   10,\n   12443,\n   6,\n   69,\n   19501,\n   11153,\n   62,\n   19,\n   380,\n   414,\n   4,\n   85,\n   4596,\n   11,\n   411,\n   1484,\n   2806,\n   28748,\n   3277,\n   4,\n   280,\n   3911,\n   8,\n   885,\n   9725,\n   69,\n   4,\n   22,\n   100,\n   802,\n   38,\n   21,\n   164,\n   7,\n   244,\n   42,\n   65,\n   621,\n   54,\n   38,\n   218,\n   75,\n   216,\n   6,\n   53,\n   5,\n   754,\n   14,\n   98,\n   171,\n   82,\n   64,\n   33,\n   10,\n   301,\n   5064,\n   6,\n   14,\n   18,\n   1256,\n   380,\n   60,\n   163,\n   8508,\n   7485,\n   1120,\n   174,\n   3480,\n   10515,\n   229,\n   14740,\n   4,\n   264,\n   189,\n   619,\n   10346,\n   11,\n   69,\n   19501,\n   30,\n   10,\n   723,\n   476,\n   4,\n   22,\n   22086,\n   13,\n   70,\n   5,\n   323,\n   8,\n   8786,\n   60,\n   10,\n   1129,\n   15,\n   10,\n   622,\n   1842,\n   11,\n   69,\n   766,\n   1166,\n   4,\n   22,\n   100,\n   216,\n   42,\n   1445,\n   3251,\n   16,\n   203,\n   2671,\n   87,\n   70,\n   9,\n   201,\n   4,\n   38,\n   67,\n   216,\n   38,\n   437,\n   95,\n   5,\n   34697,\n   72,\n   3480,\n   1395,\n   12881,\n   5,\n   21341,\n   9,\n   5,\n   1842,\n   4,\n   125,\n   5,\n   476,\n   14,\n   39582,\n   163,\n   8508,\n   7485,\n   1120,\n   18,\n   4085,\n   21,\n   414,\n   5774,\n   9,\n   9186,\n   11729,\n   31,\n   12125,\n   12,\n   13139,\n   44392,\n   15029,\n   4,\n   85,\n   1364,\n   15,\n   10,\n   2007,\n   32093,\n   9322,\n   53,\n   1239,\n   24,\n   7,\n   10,\n   203,\n   723,\n   672,\n   6,\n   309,\n   7,\n   886,\n   3073,\n   3067,\n   824,\n   11,\n   764,\n   2659,\n   4,\n   407,\n   239,\n   6,\n   14,\n   24,\n   16,\n   602,\n   292,\n   25705,\n   6,\n   10,\n   38676,\n   219,\n   9,\n   11593,\n   17385,\n   6,\n   10633,\n   8,\n   41,\n   42466,\n   118,\n   10974,\n   6,\n   8,\n   55,\n   87,\n   843,\n   323,\n   813,\n   7,\n   3008,\n   15948,\n   15,\n   316,\n   82,\n   4,\n   252,\n   32,\n   37213,\n   411,\n   33473,\n   31,\n   9398,\n   8,\n   12956,\n   30712,\n   106,\n   88,\n   411,\n   11940,\n   4,\n   22,\n   133,\n   4864,\n   9,\n   5,\n   9398,\n   8,\n   11940,\n   1186,\n   31,\n   973,\n   7,\n   1510,\n   8,\n   680,\n   130,\n   4095,\n   8,\n   920,\n   15029,\n   6,\n   65,\n   21771,\n   1763,\n   8,\n   65,\n   2138,\n   8,\n   2761,\n   12,\n   179,\n   12,\n   4656,\n   1763,\n   60,\n   5,\n   1131,\n   1312,\n   26,\n   11,\n   10,\n   445,\n   4,\n   20,\n   3206,\n   9,\n   15948,\n   16,\n   7,\n   28,\n   8144,\n   62,\n   273,\n   4,\n   96,\n   628,\n   494,\n   6,\n   5,\n   1131,\n   1312,\n   16,\n   1884,\n   7,\n   946,\n   10,\n   7362,\n   13,\n   70,\n   316,\n   1484,\n   4,\n   1398,\n   18,\n   141,\n   5,\n   2422,\n   12313,\n   1364,\n   6,\n   309,\n   7,\n   886,\n   3073,\n   3067,\n   824,\n   4,\n   9867,\n   6,\n   110,\n   2138,\n   782,\n   10,\n   12855,\n   7,\n   1871,\n   39,\n   301,\n   6,\n   50,\n   23,\n   513,\n   120,\n   160,\n   9,\n   11481,\n   26499,\n   6,\n   8,\n   47,\n   214,\n   2882,\n   7,\n   492,\n   123,\n   65,\n   9,\n   14314,\n   4,\n   125,\n   172,\n   24,\n   4072,\n   66,\n   14,\n   110,\n   12855,\n   16,\n   45,\n   10,\n   914,\n   13,\n   123,\n   6,\n   8,\n   24,\n   18,\n   1402,\n   39,\n   809,\n   74,\n   10363,\n   24,\n   4,\n   2486,\n   2138,\n   64,\n   172,\n   120,\n   15,\n   10,\n   107,\n   12,\n   3479,\n   2445,\n   889,\n   13,\n   10,\n   12855,\n   567,\n   31,\n   41,\n   6757,\n   12125,\n   54,\n   962,\n   4,\n   5359,\n   14,\n   40,\n   173,\n   66,\n   480,\n   50,\n   45,\n   6,\n   8,\n   86,\n   115,\n   422,\n   66,\n   13,\n   123,\n   4,\n   28013,\n   6,\n   47,\n   8,\n   110,\n   2138,\n   115,\n   356,\n   13,\n   277,\n   13160,\n   12,\n   26111,\n   12125,\n   891,\n   101,\n   31954,\n   480,\n   224,\n   6,\n   80,\n   55,\n   10384,\n   6,\n   147,\n   5,\n   12125,\n   18,\n   12855,\n   965,\n   75,\n   14756,\n   13,\n   39,\n   2761,\n   6,\n   5,\n   13160,\n   4,\n   125,\n   2085,\n   110,\n   12855,\n   16,\n   10,\n   914,\n   13,\n   39,\n   2761,\n   2],\n  'attention_mask': [1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1],\n  'labels': [0,\n   1301,\n   19678,\n   163,\n   8508,\n   7485,\n   1120,\n   1276,\n   7,\n   492,\n   10,\n   12855,\n   7,\n   10,\n   12443,\n   479,\n   50118,\n   250,\n   92,\n   3034,\n   586,\n   1147,\n   69,\n   7096,\n   15220,\n   28748,\n   3277,\n   13,\n   411,\n   12855,\n   1484,\n   479,\n   2]},\n {'input_ids': [0,\n   1640,\n   16256,\n   43,\n   4148,\n   5,\n   231,\n   212,\n   9,\n   587,\n   8008,\n   6,\n   764,\n   3071,\n   35168,\n   8,\n   5815,\n   315,\n   28561,\n   2794,\n   66,\n   11,\n   760,\n   9,\n   1105,\n   6,\n   39062,\n   1057,\n   927,\n   841,\n   23,\n   5,\n   25281,\n   2689,\n   11,\n   764,\n   3071,\n   6,\n   886,\n   4,\n   20,\n   3575,\n   5852,\n   21,\n   5,\n   78,\n   655,\n   5454,\n   815,\n   10433,\n   914,\n   480,\n   10,\n   10025,\n   92,\n   14131,\n   13,\n   5,\n   232,\n   18,\n   2674,\n   2414,\n   11,\n   10,\n   1212,\n   63,\n   40228,\n   56,\n   648,\n   7,\n   28527,\n   4,\n   9430,\n   3916,\n   2787,\n   5,\n   814,\n   13,\n   4944,\n   6,\n   18265,\n   5957,\n   3350,\n   4894,\n   23908,\n   1602,\n   5,\n   1151,\n   1827,\n   22,\n   33272,\n   9,\n   10,\n   92,\n   3567,\n   13,\n   470,\n   4191,\n   72,\n   7817,\n   124,\n   23,\n   4338,\n   31,\n   14,\n   17832,\n   4783,\n   1559,\n   122,\n   24,\n   18,\n   543,\n   45,\n   7,\n   619,\n   10,\n   1402,\n   22531,\n   4,\n   13379,\n   4740,\n   15331,\n   6,\n   12474,\n   25124,\n   35517,\n   8,\n   7782,\n   2178,\n   38232,\n   7,\n   146,\n   426,\n   55,\n   3571,\n   58,\n   70,\n   233,\n   9,\n   5,\n   1026,\n   3693,\n   13989,\n   676,\n   4,\n   40308,\n   29130,\n   58,\n   7460,\n   7,\n   694,\n   4149,\n   23,\n   5,\n   253,\n   9,\n   349,\n   457,\n   4,\n   1648,\n   55,\n   11676,\n   352,\n   6,\n   3016,\n   426,\n   58,\n   5668,\n   30,\n   4511,\n   4518,\n   14,\n   794,\n   6666,\n   472,\n   422,\n   19,\n   5,\n   1011,\n   31,\n   1718,\n   12,\n   17230,\n   66,\n   137,\n   6475,\n   7,\n   1451,\n   5,\n   9375,\n   7551,\n   4,\n   287,\n   5,\n   13989,\n   12273,\n   7,\n   2458,\n   5,\n   1786,\n   9,\n   63,\n   291,\n   212,\n   191,\n   6,\n   24,\n   18,\n   543,\n   7,\n   30030,\n   95,\n   141,\n   203,\n   5,\n   1267,\n   34,\n   18467,\n   11,\n   5,\n   29970,\n   675,\n   4,\n   2597,\n   1613,\n   16,\n   5,\n   4724,\n   7,\n   19665,\n   1741,\n   19,\n   5,\n   1492,\n   9,\n   5,\n   177,\n   13,\n   10,\n   386,\n   4,\n   21226,\n   5332,\n   32,\n   723,\n   87,\n   655,\n   137,\n   150,\n   5,\n   346,\n   9,\n   893,\n   963,\n   34,\n   7113,\n   31,\n   158,\n   11,\n   5,\n   8008,\n   637,\n   7,\n   291,\n   11,\n   570,\n   4,\n   83,\n   617,\n   237,\n   32,\n   278,\n   7,\n   28,\n   355,\n   30,\n   2760,\n   4,\n   374,\n   299,\n   9,\n   42,\n   6,\n   5,\n   92,\n   191,\n   16,\n   5,\n   78,\n   9,\n   10,\n   92,\n   1897,\n   1012,\n   8,\n   433,\n   659,\n   432,\n   19,\n   7481,\n   6,\n   4944,\n   8,\n   35232,\n   10699,\n   966,\n   68,\n   5987,\n   153,\n   81,\n   799,\n   107,\n   4,\n   152,\n   1955,\n   189,\n   18100,\n   13276,\n   5,\n   68,\n   245,\n   4,\n   134,\n   325,\n   682,\n   1199,\n   30,\n   987,\n   25106,\n   13,\n   5,\n   2370,\n   2275,\n   815,\n   6,\n   5,\n   16386,\n   1037,\n   1267,\n   11,\n   5,\n   232,\n   6,\n   53,\n   24,\n   3372,\n   10,\n   7182,\n   20418,\n   11,\n   923,\n   9,\n   5,\n   986,\n   13989,\n   432,\n   4,\n   767,\n   7,\n   4720,\n   8214,\n   34714,\n   6,\n   1029,\n   12,\n   42205,\n   1945,\n   8,\n   394,\n   9,\n   5,\n   92,\n   13989,\n   3468,\n   6,\n   5854,\n   412,\n   10433,\n   2009,\n   6,\n   22,\n   627,\n   539,\n   8,\n   5,\n   177,\n   1495,\n   34,\n   1410,\n   15,\n   8617,\n   113,\n   11,\n   5,\n   121,\n   4,\n   104,\n   7586,\n   91,\n   2046,\n   99,\n   74,\n   3871,\n   654,\n   107,\n   434,\n   11,\n   144,\n   97,\n   4510,\n   34,\n   57,\n   2984,\n   11,\n   5,\n   78,\n   80,\n   1724,\n   9,\n   5,\n   13989,\n   4,\n   8214,\n   34714,\n   108,\n   950,\n   16,\n   10,\n   2654,\n   1246,\n   9,\n   42,\n   6379,\n   7791,\n   4,\n   91,\n   7448,\n   472,\n   145,\n   3148,\n   66,\n   9,\n   2992,\n   2644,\n   142,\n   9,\n   10,\n   3078,\n   6064,\n   19,\n   10,\n   11025,\n   1380,\n   45,\n   98,\n   251,\n   536,\n   4,\n   152,\n   983,\n   1191,\n   6,\n   151,\n   841,\n   32,\n   421,\n   7,\n   4562,\n   5854,\n   412,\n   18,\n   1273,\n   983,\n   12319,\n   136,\n   188,\n   469,\n   412,\n   6,\n   277,\n   92,\n   950,\n   442,\n   49,\n   13989,\n   7323,\n   4,\n   623,\n   968,\n   4251,\n   229,\n   5870,\n   8,\n   871,\n   12470,\n   40,\n   1004,\n   66,\n   13,\n   5854,\n   8,\n   188,\n   469,\n   412,\n   4067,\n   4,\n   22,\n   170,\n   214,\n   95,\n   15,\n   2],\n  'attention_mask': [1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1,\n   1],\n  'labels': [0,\n   133,\n   291,\n   212,\n   13989,\n   191,\n   3772,\n   42,\n   983,\n   479,\n   50118,\n   17608,\n   34,\n   1714,\n   8617,\n   187,\n   63,\n   17692,\n   11,\n   8008,\n   479,\n   50118,\n   6323,\n   864,\n   549,\n   1492,\n   2624,\n   5391,\n   9686,\n   8,\n   12291,\n   240,\n   7,\n   464,\n   479,\n   2]}]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [tokenized_cnn[i] for i in range(2)]\n",
    "features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[    0,  1640, 16256,  ...,    39,  2761,     2],\n        [    0,  1640, 16256,  ...,    95,    15,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[    0,  1301, 19678,   163,  8508,  7485,  1120,  1276,     7,   492,\n            10, 12855,     7,    10, 12443,   479, 50118,   250,    92,  3034,\n           586,  1147,    69,  7096, 15220, 28748,  3277,    13,   411, 12855,\n          1484,   479,     2,  -100,  -100,  -100],\n        [    0,   133,   291,   212, 13989,   191,  3772,    42,   983,   479,\n         50118, 17608,    34,  1714,  8617,   187,    63, 17692,    11,  8008,\n           479, 50118,  6323,   864,   549,  1492,  2624,  5391,  9686,     8,\n         12291,   240,     7,   464,   479,     2]]), 'decoder_input_ids': tensor([[    2,     0,  1301, 19678,   163,  8508,  7485,  1120,  1276,     7,\n           492,    10, 12855,     7,    10, 12443,   479, 50118,   250,    92,\n          3034,   586,  1147,    69,  7096, 15220, 28748,  3277,    13,   411,\n         12855,  1484,   479,     2,     1,     1],\n        [    2,     0,   133,   291,   212, 13989,   191,  3772,    42,   983,\n           479, 50118, 17608,    34,  1714,  8617,   187,    63, 17692,    11,\n          8008,   479, 50118,  6323,   864,   549,  1492,  2624,  5391,  9686,\n             8, 12291,   240,     7,   464,   479]])}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ_data_collator(features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "tokenized_cnn.set_format(\"torch\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 1\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_cnn,\n",
    "    shuffle=True,\n",
    "    collate_fn=summ_data_collator,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_cnn,\n",
    "    collate_fn=summ_data_collator,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(models[\"summarization\"].parameters(), lr=2e-5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    models[\"summarization\"], optimizer, train_dataloader, eval_dataloader\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 1\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch progress:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e091775425c34e95a2d09a15715091ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch step:   0%|          | 0/13368 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ef1bc7412414b6d8bfb2deca44ea127"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "# progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in tqdm(range(num_train_epochs), total=num_train_epochs, desc=\"Epoch progress\"):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=\"Epoch step\", leave=False):\n",
    "        # pass through model\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "            )  # aha! we can plug the generation parameters here\n",
    "\n",
    "            generated_tokens = accelerator.pad_across_processes(\n",
    "                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # If we did not pad to max length, we need to pad the labels too\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()\n",
    "            labels = accelerator.gather(labels).cpu().numpy()\n",
    "\n",
    "            # Replace -100 in the labels as we can't decode them\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            if isinstance(generated_tokens, tuple):\n",
    "                generated_tokens = generated_tokens[0]\n",
    "            decoded_preds = tokenizer.batch_decode(\n",
    "                generated_tokens, skip_special_tokens=True\n",
    "            )\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            decoded_preds, decoded_labels = postprocess_text(\n",
    "                decoded_preds, decoded_labels\n",
    "            )\n",
    "\n",
    "            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    # Compute metrics\n",
    "    result = rouge_score.compute()\n",
    "    # Extract the median ROUGE scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    print(f\"Epoch {epoch}:\", result)\n",
    "\n",
    "    output_dir = \"./test_summ_train\"\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
