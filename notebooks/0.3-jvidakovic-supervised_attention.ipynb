{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "The goal of this notebook is to explore the attention patterns of transformer-based language models on document-level event detection.\n",
    "DoCEE dataset is used, and for the model we use RoBERTa-base.\n",
    "\n",
    "First, we're gonna explore the pretrained model. We need to load the model, which includes:\n",
    "    - loading the tokenizer\n",
    "    - loading the config file\n",
    "    - loading the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaPreTrainedModel: ['roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.11.intermediate.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'lm_head.bias', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.key.weight']\n",
      "- This IS expected if you are initializing RobertaPreTrainedModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaPreTrainedModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaPreTrainedModel()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaPreTrainedModel, RobertaTokenizerFast\n",
    "\n",
    "device = \"cuda\"\n",
    "model_name_or_path = \"roberta-base\"\n",
    "cache_dir = \"../pretrained_models\"\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name_or_path,\n",
    "    cache_dir=cache_dir\n",
    ")\n",
    "\n",
    "model = RobertaPreTrainedModel.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    cache_dir\n",
    ").to(device)\n",
    "\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we need to load the dataset, and we'll use the training split for exploration.\n",
    "We'll load only 10 examples, because we don't really need more than that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                              title  \\\n0           0  Vietnam reelects conservative Nguyễn Phú Trọng...   \n1           1  At least 42 people are killed in a bus crash i...   \n2           2  At least 27 migrants die in a shipwreck in the...   \n3           3  Colten Treu faces charges of vehicular homicid...   \n4           4  Hours after the announcement, Morales resigns ...   \n\n                                                text  \\\n0  Vietnam's Communist Party Wednesday re-elected...   \n1  Another 43 people were injured when the bus ca...   \n2  At least 27 migrants have died off the Turkish...   \n3  Colten Treu, 21, and his roommate both told au...   \n4  Bolivian President Evo Morales has resigned af...   \n\n                                      event_type  \\\n0               Government Job change - Election   \n1                                     Road Crash   \n2                                      Shipwreck   \n3                                     Road Crash   \n4  Government Job change - Resignation_Dismissal   \n\n                                           arguments           date  \\\n0  [{'start': 0, 'end': 24, 'type': 'Candidates a...   January 2016   \n1  [{'start': 8, 'end': 29, 'type': 'Casualties a...   October 2006   \n2  [{'start': 0, 'end': 29, 'type': 'Casualties a...  February 2016   \n3  [{'start': 183, 'end': 207, 'type': 'Number of...  November 2018   \n4  [{'start': 0, 'end': 17, 'type': 'Position', '...  November 2019   \n\n                                            metadata  \n0        ['(AP via ABC News)', '(Channel NewsAsia)']  \n1                                          ['(BBC)']  \n2  ['(ANSAmed)', '(Leadership)', '(news.com.au)',...  \n3                             ['(KSTP)', '(Oxygen)']  \n4                   ['(BBC News)', '(The Guardian)']  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>text</th>\n      <th>event_type</th>\n      <th>arguments</th>\n      <th>date</th>\n      <th>metadata</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Vietnam reelects conservative Nguyễn Phú Trọng...</td>\n      <td>Vietnam's Communist Party Wednesday re-elected...</td>\n      <td>Government Job change - Election</td>\n      <td>[{'start': 0, 'end': 24, 'type': 'Candidates a...</td>\n      <td>January 2016</td>\n      <td>['(AP via ABC News)', '(Channel NewsAsia)']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>At least 42 people are killed in a bus crash i...</td>\n      <td>Another 43 people were injured when the bus ca...</td>\n      <td>Road Crash</td>\n      <td>[{'start': 8, 'end': 29, 'type': 'Casualties a...</td>\n      <td>October 2006</td>\n      <td>['(BBC)']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>At least 27 migrants die in a shipwreck in the...</td>\n      <td>At least 27 migrants have died off the Turkish...</td>\n      <td>Shipwreck</td>\n      <td>[{'start': 0, 'end': 29, 'type': 'Casualties a...</td>\n      <td>February 2016</td>\n      <td>['(ANSAmed)', '(Leadership)', '(news.com.au)',...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Colten Treu faces charges of vehicular homicid...</td>\n      <td>Colten Treu, 21, and his roommate both told au...</td>\n      <td>Road Crash</td>\n      <td>[{'start': 183, 'end': 207, 'type': 'Number of...</td>\n      <td>November 2018</td>\n      <td>['(KSTP)', '(Oxygen)']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Hours after the announcement, Morales resigns ...</td>\n      <td>Bolivian President Evo Morales has resigned af...</td>\n      <td>Government Job change - Resignation_Dismissal</td>\n      <td>[{'start': 0, 'end': 17, 'type': 'Position', '...</td>\n      <td>November 2019</td>\n      <td>['(BBC News)', '(The Guardian)']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "keep_only = 10\n",
    "train_df = pd.read_csv(\"../data/docee/train_all.csv\")[:keep_only]\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===text=== \n",
      "Field type: <class 'list'>\n",
      "Field length : 10\n",
      "Type of element: <class 'str'>\n",
      "First element = Vietnam's Communist Party Wednesday re-elected its 71-year-old chief for a second term, an expected outcome that sees the conservative pro-China ideologue cementing his hold on power.\n",
      "The party's congress elected Nguyen Phu Trong (pronounced Noo-yen Foo Chong) to a 19-member Politburo, the all-powerful body that handles the day-to-day affairs of the government and the party. In a subsequent vote, he was immediately chosen as the general-secretary, the de facto No. 1 leader of the country.\n",
      "The announcement was made on the official Vietnam News Agency's website.\n",
      "Officials said Deputy Prime Minister Nguyen Xuan Phuc was also elected to the Politburo, and he is now expected to become the prime minister. He will replace Nguyen Tan Dung, who had had led economic reforms over the last 10 years and had harbored ambitions for the top job. His challenge, however, was snuffed by Trong's supporters during the weeklong party congress that ends Thursday.\n",
      "The third most important member elected to the Politburo was Minister of Public Security Tran Dai Quang, who will be the country's new president, said the officials, who spoke on condition of anonymity because they were not authorized to speak to the media.\n",
      "The general secretary, the prime minister and the president, along with the chairman of the National Assembly, are the four key members in the collective leadership represented by the Politburo, and the 180-member Central Committee, which handles policy.\n",
      "The renewal of the leadership means little change for Vietnam.\n",
      "Trong is expected to continue to push Dung's economic reforms. Despite having a reputation for being pro-China he is not likely to be totally subservient to Beijing as that would risk massive anger from ordinary Vietnamese who harbor a deep dislike and historical suspicion of China.\n",
      "\"Many people were afraid that a conservative trend would prevail if Mr. Trong is re-elected. But ... whoever they may be, and however conservative they may be, when they are at the helm they are under pressure to carry out reforms,\" Le Hong Hiep, a visiting Vietnamese fellow at the Institute of Southeast Asia Studies in Singapore, told The Associated Press.\n",
      "The Communist Party is entitled by the constitution to govern and Vietnam's 93 million people have no direct role in electing the leaders of the 4.5 million-member party.\n",
      "It is believed that as a compromise with Prime Minister Dung's camp, Trong will not serve his full five-year term but may hand over power to another leader mid-way.\n",
      "Dung was seen as a pro-business leader who investors believe would have continued with economic reforms he set in motion 10 years ago that helped Vietnam attract a flood of foreign investment and was partly responsible for tripling the per capita GDP to $2,100. He was also seen as standing up to China, which is making aggressive territorial claims in the South China Sea and building islands, much to the chagrin of Southeast Asia nations who have conflicting claims in the waters.\n",
      "China sent an oil rig into Vietnamese waters in 2014, triggering a massive backlash among Vietnamese, including attacks on Chinese businesses. Dung was vocal in criticizing China then, while Trong was muted.\n",
      "Despite Trong's reputation as being an anti-thesis of Dung, the reality is not so black-and-white. Observers agree that the economic reforms Dung started have the blessings of the collective leadership, including Trong.\n",
      "A clear example came when a plenum of the outgoing Central Committee overwhelmingly endorsed Vietnam joining the Trans-Pacific Partnership, a U.S. led free-trade initiative.\n",
      "As for China, Trong will likely not risk the ire of the public by being soft if Beijing's assertiveness impinges on Vietnam territorial integrity.\n",
      "The cosmetic change in the leadership also means that Vietnam has no immediate hopes for political reforms, even though there is a desire in the government to loosen up on public freedoms.\n",
      "\"They are faced with a dilemma. They want to maintain the one-party rule and at the same time they want to have reforms in some limited areas,\" said Hiep, the Vietnamese scholar.\n",
      "\"Their trend is to change, but they will still be cautious, because the party's ultimate goal is to maintain their monopoly on power,\" Hiep said.\n",
      " ==labels== \n",
      "Field type: <class 'list'>\n",
      "Field length : 10\n",
      "Type of element: <class 'str'>\n",
      "First element = Government Job change - Election\n",
      " arguments= \n",
      "Field type: <class 'list'>\n",
      "Field length : 10\n",
      "Type of element: <class 'list'>\n",
      "First element = [Argument(start=0, end=24, type='Candidates and their parties', text=\"Vietnam's Communist Party\"), Argument(start=26, end=34, type='Date', text='Wednesday'), Argument(start=213, end=228, type='Candidates and their parties', text='Nguyen Phu Trong'), Argument(start=604, end=619, type='Candidates and their parties', text='Nguyen Xuan Phuc'), Argument(start=2657, end=2663, type='Location', text='Vietnam')]\n"
     ]
    }
   ],
   "source": [
    "from src.data import DoceeDataset\n",
    "\n",
    "train_dataset = DoceeDataset(train_df, tokenizer=tokenizer)\n",
    "train_dataset.inspect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Argument(start=0, end=24, type='Candidates and their parties', text=\"Vietnam's Communist Party\"), Argument(start=26, end=34, type='Date', text='Wednesday'), Argument(start=213, end=228, type='Candidates and their parties', text='Nguyen Phu Trong'), Argument(start=604, end=619, type='Candidates and their parties', text='Nguyen Xuan Phuc'), Argument(start=2657, end=2663, type='Location', text='Vietnam')]\n"
     ]
    }
   ],
   "source": [
    "example_arg = train_dataset.arguments[0]\n",
    "print(example_arg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that for some examples, arguments is a list. The list contains multiple dictionaries, each representing a single argument. Each argument has the following information:\n",
    "    - start -- denotes the starting index of the argument (character index?)\n",
    "    - end   -- denotes the ending index of the argument\n",
    "    - type  -- denotes the argument type\n",
    "    - text  -- text which is labeled as the argument"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument(start=0, end=24, type='Candidates and their parties', text=\"Vietnam's Communist Party\")\n"
     ]
    }
   ],
   "source": [
    "first_arg = example_arg[0]\n",
    "print(first_arg)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
